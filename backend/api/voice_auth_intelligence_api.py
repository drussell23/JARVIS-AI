"""
Voice Authentication Intelligence API
=====================================

Comprehensive FastAPI endpoints for testing and monitoring the enhanced
voice authentication intelligence system.

Features exposed:
- LangGraph adaptive authentication reasoning
- Langfuse audit trail and session management
- ChromaDB voice pattern store and anti-spoofing
- Helicone-style voice processing cache
- Multi-factor authentication fusion
- Progressive voice feedback

Author: JARVIS AI System
Version: 2.0.0
"""

import asyncio
import base64
import logging
import time
from datetime import datetime
from typing import Any, Dict, List, Optional
from uuid import uuid4

import numpy as np
from fastapi import APIRouter, HTTPException, UploadFile, File, Query, Body
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/voice-auth-intelligence", tags=["voice_auth_intelligence"])


# ============================================================================
# Request/Response Models
# ============================================================================

class AuthenticateEnhancedRequest(BaseModel):
    """Request model for enhanced authentication."""
    audio_base64: Optional[str] = Field(None, description="Base64 encoded audio data")
    speaker_name: str = Field(default="Derek", description="Speaker name to verify against")
    use_adaptive: bool = Field(default=True, description="Use LangGraph adaptive reasoning")
    max_attempts: int = Field(default=3, description="Maximum retry attempts")
    require_watch: bool = Field(default=False, description="Require Apple Watch proximity")


class SimulateAuthRequest(BaseModel):
    """Request model for simulating authentication scenarios."""
    scenario: str = Field(..., description="Scenario: 'success', 'borderline', 'sick_voice', 'replay_attack', 'unknown_speaker', 'noisy_environment'")
    speaker_name: str = Field(default="Derek", description="Speaker name")
    voice_confidence: Optional[float] = Field(None, description="Override voice confidence (0-1)")
    behavioral_confidence: Optional[float] = Field(None, description="Override behavioral confidence (0-1)")


class StorePatternRequest(BaseModel):
    """Request model for storing voice patterns."""
    speaker_name: str = Field(..., description="Speaker name")
    pattern_type: str = Field(..., description="Pattern type: 'rhythm', 'phrase', 'environment', 'emotion', 'audio_fingerprint'")
    embedding: List[float] = Field(..., description="192-dimensional embedding vector")
    metadata: Optional[Dict[str, Any]] = Field(default_factory=dict, description="Additional metadata")


class ChallengeQuestionRequest(BaseModel):
    """Request model for challenge question verification."""
    speaker_name: str = Field(default="Derek", description="Speaker name")
    answer: str = Field(..., description="User's answer to the challenge question")
    challenge_id: str = Field(..., description="Challenge question ID from previous response")


# ============================================================================
# Service Initialization
# ============================================================================

# Lazy-loaded service instances
_speaker_service = None
_voice_unlock_system = None
_pattern_store = None
_audit_trail = None
_cache = None
_feedback_generator = None
_multi_factor_engine = None


async def get_speaker_service():
    """Get or initialize the speaker verification service."""
    global _speaker_service
    if _speaker_service is None:
        try:
            from voice.speaker_verification_service import get_speaker_service as get_svc
            _speaker_service = get_svc()
            logger.info("✅ Speaker verification service initialized for API")
        except Exception as e:
            logger.error(f"Failed to initialize speaker service: {e}")
            raise HTTPException(status_code=503, detail=f"Speaker service unavailable: {e}")
    return _speaker_service


async def get_pattern_store():
    """Get or initialize the ChromaDB voice pattern store."""
    global _pattern_store
    if _pattern_store is None:
        try:
            from voice.speaker_verification_service import VoicePatternStore
            _pattern_store = VoicePatternStore()
            await _pattern_store.initialize()
            logger.info("✅ ChromaDB voice pattern store initialized")
        except Exception as e:
            logger.warning(f"Pattern store unavailable: {e}")
            return None
    return _pattern_store


async def get_audit_trail():
    """Get or initialize the Langfuse audit trail."""
    global _audit_trail
    if _audit_trail is None:
        try:
            from voice.speaker_verification_service import AuthenticationAuditTrail
            _audit_trail = AuthenticationAuditTrail()
            await _audit_trail.initialize()
            logger.info("✅ Langfuse audit trail initialized")
        except Exception as e:
            logger.warning(f"Audit trail unavailable: {e}")
            return None
    return _audit_trail


async def get_voice_cache():
    """Get or initialize the voice processing cache."""
    global _cache
    if _cache is None:
        try:
            from voice.speaker_verification_service import VoiceProcessingCache
            _cache = VoiceProcessingCache(max_size=100, ttl_seconds=300)
            logger.info("✅ Voice processing cache initialized")
        except Exception as e:
            logger.warning(f"Cache unavailable: {e}")
            return None
    return _cache


async def get_feedback_generator():
    """Get or initialize the voice feedback generator."""
    global _feedback_generator
    if _feedback_generator is None:
        try:
            from voice.speaker_verification_service import VoiceFeedbackGenerator
            _feedback_generator = VoiceFeedbackGenerator(user_name="Derek")
            logger.info("✅ Voice feedback generator initialized")
        except Exception as e:
            logger.warning(f"Feedback generator unavailable: {e}")
            return None
    return _feedback_generator


async def get_multi_factor_engine():
    """Get or initialize the multi-factor fusion engine."""
    global _multi_factor_engine
    if _multi_factor_engine is None:
        try:
            from voice.speaker_verification_service import MultiFactorAuthFusionEngine
            _multi_factor_engine = MultiFactorAuthFusionEngine()
            logger.info("✅ Multi-factor fusion engine initialized")
        except Exception as e:
            logger.warning(f"Multi-factor engine unavailable: {e}")
            return None
    return _multi_factor_engine


# ============================================================================
# Health & Status Endpoints
# ============================================================================

@router.get("/status")
async def get_intelligence_status():
    """
    Get comprehensive status of all voice authentication intelligence components.

    Returns status of:
    - LangGraph adaptive reasoning
    - Langfuse audit trail
    - ChromaDB pattern store
    - Voice processing cache
    - Multi-factor fusion engine
    """
    status = {
        "timestamp": datetime.utcnow().isoformat(),
        "components": {}
    }

    # Check LangGraph
    try:
        from langgraph.graph import StateGraph
        status["components"]["langgraph"] = {"available": True, "status": "ready"}
    except ImportError:
        status["components"]["langgraph"] = {"available": False, "status": "not_installed"}

    # Check Langfuse
    try:
        from langfuse import Langfuse
        audit_trail = await get_audit_trail()
        status["components"]["langfuse"] = {
            "available": True,
            "status": "ready" if audit_trail else "initialization_failed",
            "initialized": audit_trail is not None
        }
    except ImportError:
        status["components"]["langfuse"] = {"available": False, "status": "not_installed"}

    # Check ChromaDB
    try:
        import chromadb
        pattern_store = await get_pattern_store()
        if pattern_store and pattern_store._initialized:
            pattern_count = pattern_store._collection.count() if pattern_store._collection else 0
            status["components"]["chromadb"] = {
                "available": True,
                "status": "ready",
                "pattern_count": pattern_count
            }
        else:
            status["components"]["chromadb"] = {"available": True, "status": "not_initialized"}
    except ImportError:
        status["components"]["chromadb"] = {"available": False, "status": "not_installed"}

    # Check Voice Cache
    cache = await get_voice_cache()
    if cache:
        cache_stats = cache.get_stats()
        status["components"]["voice_cache"] = {
            "available": True,
            "status": "ready",
            "stats": cache_stats
        }
    else:
        status["components"]["voice_cache"] = {"available": False, "status": "unavailable"}

    # Check Multi-Factor Engine
    mf_engine = await get_multi_factor_engine()
    status["components"]["multi_factor_fusion"] = {
        "available": mf_engine is not None,
        "status": "ready" if mf_engine else "unavailable",
        "weights": mf_engine.weights if mf_engine else None
    }

    # Check Speaker Service
    try:
        speaker_svc = await get_speaker_service()
        status["components"]["speaker_verification"] = {
            "available": True,
            "status": "ready",
            "has_enhanced_verification": hasattr(speaker_svc, 'verify_speaker_enhanced')
        }
    except Exception as e:
        status["components"]["speaker_verification"] = {
            "available": False,
            "status": "error",
            "error": str(e)
        }

    # Overall health
    all_ready = all(
        c.get("status") == "ready" or c.get("available") == False
        for c in status["components"].values()
    )
    status["overall_health"] = "healthy" if all_ready else "degraded"

    return status


@router.get("/health")
async def health_check():
    """Quick health check for the voice auth intelligence API."""
    return {
        "status": "ok",
        "service": "voice_auth_intelligence",
        "timestamp": datetime.utcnow().isoformat()
    }


# ============================================================================
# Authentication Endpoints
# ============================================================================

@router.post("/authenticate/enhanced")
async def authenticate_enhanced(request: AuthenticateEnhancedRequest):
    """
    Perform enhanced voice authentication with all intelligence features.

    This endpoint uses:
    - LangGraph adaptive reasoning for intelligent retries
    - Multi-factor fusion (voice + behavioral + context)
    - Langfuse audit trail for full transparency
    - ChromaDB for anti-spoofing detection
    - Voice processing cache for cost optimization

    Returns detailed authentication result with reasoning trace.
    """
    start_time = time.time()

    try:
        # Get services
        speaker_service = await get_speaker_service()
        audit_trail = await get_audit_trail()

        # Start audit session
        session_id = None
        if audit_trail:
            session_id = audit_trail.start_session(
                user_id=request.speaker_name,
                device="api_test"
            )

        # Prepare audio data
        if request.audio_base64:
            audio_bytes = base64.b64decode(request.audio_base64)
        else:
            # Generate test audio (silence) for API testing
            audio_bytes = np.zeros(16000, dtype=np.float32).tobytes()
            logger.info("No audio provided, using test silence")

        # Perform enhanced verification
        if hasattr(speaker_service, 'verify_speaker_enhanced'):
            result = await speaker_service.verify_speaker_enhanced(
                audio_bytes,
                speaker_name=request.speaker_name,
                context={
                    "use_adaptive": request.use_adaptive,
                    "max_attempts": request.max_attempts,
                    "source": "api_test"
                }
            )
        else:
            # Fallback to basic verification
            result = {
                "verified": False,
                "confidence": 0.0,
                "error": "Enhanced verification not available"
            }

        # End audit session
        if audit_trail and session_id:
            outcome = "authenticated" if result.get("verified") else "denied"
            audit_trail.end_session(session_id, outcome)

        processing_time_ms = (time.time() - start_time) * 1000

        return {
            "success": True,
            "authenticated": result.get("verified", False),
            "confidence": result.get("confidence", 0.0),
            "voice_confidence": result.get("voice_confidence", 0.0),
            "behavioral_confidence": result.get("behavioral_confidence", 0.0),
            "context_confidence": result.get("context_confidence", 0.0),
            "feedback": result.get("feedback", {}),
            "trace_id": result.get("trace_id"),
            "session_id": session_id,
            "threat_detected": result.get("threat_detected"),
            "processing_time_ms": processing_time_ms,
            "services_used": {
                "langgraph_adaptive": request.use_adaptive,
                "langfuse_audit": audit_trail is not None,
                "chromadb_patterns": True,
                "voice_cache": True
            }
        }

    except Exception as e:
        logger.error(f"Enhanced authentication error: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/authenticate/simulate")
async def simulate_authentication(request: SimulateAuthRequest):
    """
    Simulate authentication scenarios for testing.

    Scenarios:
    - success: High confidence match
    - borderline: Confidence near threshold (triggers challenge question)
    - sick_voice: Voice anomaly detected
    - replay_attack: Detected replay attack
    - unknown_speaker: Unknown voice
    - noisy_environment: Background noise issues

    Useful for testing feedback messages and UI integration.
    """
    feedback_gen = await get_feedback_generator()
    audit_trail = await get_audit_trail()

    # Start audit session for simulation
    session_id = None
    if audit_trail:
        session_id = audit_trail.start_session(
            user_id=request.speaker_name,
            device="simulation"
        )

    # Define scenario parameters
    scenarios = {
        "success": {
            "verified": True,
            "voice_confidence": request.voice_confidence or 0.94,
            "behavioral_confidence": request.behavioral_confidence or 0.96,
            "context_confidence": 0.98,
            "threat": None
        },
        "borderline": {
            "verified": False,
            "voice_confidence": request.voice_confidence or 0.72,
            "behavioral_confidence": request.behavioral_confidence or 0.92,
            "context_confidence": 0.95,
            "threat": None,
            "trigger_challenge": True
        },
        "sick_voice": {
            "verified": True,
            "voice_confidence": request.voice_confidence or 0.68,
            "behavioral_confidence": request.behavioral_confidence or 0.94,
            "context_confidence": 0.96,
            "threat": None,
            "illness_detected": True
        },
        "replay_attack": {
            "verified": False,
            "voice_confidence": 0.89,
            "behavioral_confidence": 0.0,
            "context_confidence": 0.50,
            "threat": "replay_attack"
        },
        "unknown_speaker": {
            "verified": False,
            "voice_confidence": 0.34,
            "behavioral_confidence": 0.20,
            "context_confidence": 0.85,
            "threat": "unknown_speaker"
        },
        "noisy_environment": {
            "verified": False,
            "voice_confidence": request.voice_confidence or 0.55,
            "behavioral_confidence": request.behavioral_confidence or 0.88,
            "context_confidence": 0.90,
            "threat": None,
            "environmental_issues": ["background_noise", "low_snr"]
        }
    }

    if request.scenario not in scenarios:
        raise HTTPException(
            status_code=400,
            detail=f"Unknown scenario. Available: {list(scenarios.keys())}"
        )

    scenario_data = scenarios[request.scenario]

    # Calculate fused confidence
    fused_confidence = (
        scenario_data["voice_confidence"] * 0.50 +
        scenario_data["behavioral_confidence"] * 0.30 +
        scenario_data["context_confidence"] * 0.20
    )

    # Generate feedback
    feedback = None
    if feedback_gen:
        if scenario_data.get("threat"):
            from voice.speaker_verification_service import ThreatType
            threat_map = {
                "replay_attack": ThreatType.REPLAY_ATTACK,
                "unknown_speaker": ThreatType.UNKNOWN_SPEAKER
            }
            feedback = feedback_gen.generate_security_alert(
                threat_map.get(scenario_data["threat"], ThreatType.NONE)
            )
        else:
            context = {
                "snr_db": 8 if request.scenario == "noisy_environment" else 18,
                "voice_changed": scenario_data.get("illness_detected", False)
            }
            feedback = feedback_gen.generate_feedback(fused_confidence, context)

    # End audit session
    if audit_trail and session_id:
        outcome = "authenticated" if scenario_data["verified"] else "denied"
        audit_trail.end_session(session_id, outcome)

    return {
        "scenario": request.scenario,
        "simulated_result": {
            "verified": scenario_data["verified"],
            "fused_confidence": round(fused_confidence, 3),
            "voice_confidence": scenario_data["voice_confidence"],
            "behavioral_confidence": scenario_data["behavioral_confidence"],
            "context_confidence": scenario_data["context_confidence"],
            "threat_detected": scenario_data.get("threat"),
            "illness_detected": scenario_data.get("illness_detected", False),
            "trigger_challenge": scenario_data.get("trigger_challenge", False),
            "environmental_issues": scenario_data.get("environmental_issues", [])
        },
        "feedback": {
            "message": feedback.message if feedback else None,
            "confidence_level": feedback.confidence_level.value if feedback else None,
            "suggestion": feedback.suggestion if feedback else None,
            "speak_aloud": feedback.speak_aloud if feedback else False
        },
        "session_id": session_id
    }


# ============================================================================
# Langfuse Audit Trail Endpoints
# ============================================================================

@router.post("/audit/session/start")
async def start_audit_session(
    user_id: str = Query(default="Derek", description="User ID"),
    device: str = Query(default="mac", description="Device type")
):
    """Start a new Langfuse audit session for tracking authentication attempts."""
    audit_trail = await get_audit_trail()
    if not audit_trail:
        raise HTTPException(status_code=503, detail="Langfuse audit trail not available")

    session_id = audit_trail.start_session(user_id, device)

    return {
        "success": True,
        "session_id": session_id,
        "user_id": user_id,
        "device": device,
        "message": f"Audit session started: {session_id}"
    }


@router.post("/audit/session/{session_id}/end")
async def end_audit_session(
    session_id: str,
    outcome: str = Query(..., description="Outcome: 'authenticated', 'denied', 'timeout', 'cancelled'")
):
    """End an audit session with the final outcome."""
    audit_trail = await get_audit_trail()
    if not audit_trail:
        raise HTTPException(status_code=503, detail="Langfuse audit trail not available")

    summary = audit_trail.end_session(session_id, outcome)

    if not summary:
        raise HTTPException(status_code=404, detail=f"Session not found: {session_id}")

    return {
        "success": True,
        "session_id": session_id,
        "outcome": outcome,
        "summary": summary
    }


@router.get("/audit/traces/recent")
async def get_recent_traces(
    speaker_name: Optional[str] = Query(None, description="Filter by speaker"),
    limit: int = Query(default=20, description="Maximum traces to return")
):
    """Get recent authentication traces from the audit trail."""
    audit_trail = await get_audit_trail()
    if not audit_trail:
        raise HTTPException(status_code=503, detail="Langfuse audit trail not available")

    traces = audit_trail.get_recent_traces(speaker_name, limit)

    return {
        "success": True,
        "count": len(traces),
        "traces": [t.to_dict() for t in traces]
    }


@router.get("/audit/trace/{trace_id}")
async def get_trace_details(trace_id: str):
    """Get detailed information about a specific authentication trace."""
    audit_trail = await get_audit_trail()
    if not audit_trail:
        raise HTTPException(status_code=503, detail="Langfuse audit trail not available")

    trace = audit_trail.get_trace(trace_id)

    if not trace:
        raise HTTPException(status_code=404, detail=f"Trace not found: {trace_id}")

    return {
        "success": True,
        "trace": trace.to_dict()
    }


# ============================================================================
# ChromaDB Pattern Store Endpoints
# ============================================================================

@router.post("/patterns/store")
async def store_voice_pattern(request: StorePatternRequest):
    """Store a voice pattern in ChromaDB for behavioral analysis and anti-spoofing."""
    pattern_store = await get_pattern_store()
    if not pattern_store or not pattern_store._initialized:
        raise HTTPException(status_code=503, detail="ChromaDB pattern store not available")

    from voice.speaker_verification_service import VoicePattern

    pattern = VoicePattern(
        pattern_id=f"pattern_{uuid4().hex[:12]}",
        speaker_name=request.speaker_name,
        pattern_type=request.pattern_type,
        embedding=np.array(request.embedding, dtype=np.float32),
        metadata=request.metadata
    )

    success = await pattern_store.store_pattern(pattern)

    return {
        "success": success,
        "pattern_id": pattern.pattern_id,
        "speaker_name": request.speaker_name,
        "pattern_type": request.pattern_type
    }


@router.post("/patterns/search")
async def search_similar_patterns(
    speaker_name: str = Query(..., description="Speaker name"),
    embedding: List[float] = Body(..., description="Query embedding"),
    pattern_type: Optional[str] = Query(None, description="Filter by pattern type"),
    top_k: int = Query(default=5, description="Number of results")
):
    """Search for similar voice patterns in ChromaDB."""
    pattern_store = await get_pattern_store()
    if not pattern_store or not pattern_store._initialized:
        raise HTTPException(status_code=503, detail="ChromaDB pattern store not available")

    results = await pattern_store.find_similar_patterns(
        np.array(embedding, dtype=np.float32),
        speaker_name,
        pattern_type,
        top_k
    )

    return {
        "success": True,
        "count": len(results),
        "patterns": results
    }


@router.post("/patterns/detect-replay")
async def detect_replay_attack(
    speaker_name: str = Query(..., description="Speaker name"),
    audio_fingerprint: str = Query(..., description="Audio SHA-256 fingerprint"),
    time_window_seconds: int = Query(default=300, description="Lookback window")
):
    """Check if audio has been used before (replay attack detection)."""
    pattern_store = await get_pattern_store()
    if not pattern_store or not pattern_store._initialized:
        raise HTTPException(status_code=503, detail="ChromaDB pattern store not available")

    is_replay, anomaly_score = await pattern_store.detect_replay_attack(
        audio_fingerprint,
        speaker_name,
        time_window_seconds
    )

    return {
        "success": True,
        "is_replay_attack": is_replay,
        "anomaly_score": anomaly_score,
        "audio_fingerprint": audio_fingerprint[:32] + "...",
        "time_window_seconds": time_window_seconds
    }


@router.get("/patterns/stats")
async def get_pattern_stats():
    """Get ChromaDB pattern store statistics."""
    pattern_store = await get_pattern_store()
    if not pattern_store or not pattern_store._initialized:
        return {
            "success": False,
            "initialized": False,
            "error": "Pattern store not available"
        }

    count = pattern_store._collection.count() if pattern_store._collection else 0

    return {
        "success": True,
        "initialized": True,
        "total_patterns": count,
        "persist_directory": pattern_store.persist_directory
    }


# ============================================================================
# Voice Cache Endpoints
# ============================================================================

@router.get("/cache/stats")
async def get_cache_stats():
    """Get voice processing cache statistics (Helicone-style cost optimization)."""
    cache = await get_voice_cache()
    if not cache:
        return {
            "success": False,
            "available": False
        }

    stats = cache.get_stats()

    return {
        "success": True,
        "available": True,
        "stats": stats
    }


@router.post("/cache/clear")
async def clear_cache():
    """Clear the voice processing cache."""
    cache = await get_voice_cache()
    if not cache:
        raise HTTPException(status_code=503, detail="Voice cache not available")

    cache.clear()

    return {
        "success": True,
        "message": "Voice processing cache cleared"
    }


# ============================================================================
# Multi-Factor Fusion Endpoints
# ============================================================================

@router.get("/multi-factor/weights")
async def get_factor_weights():
    """Get current multi-factor authentication weights."""
    mf_engine = await get_multi_factor_engine()
    if not mf_engine:
        raise HTTPException(status_code=503, detail="Multi-factor engine not available")

    return {
        "success": True,
        "base_weights": mf_engine.base_weights,
        "current_weights": mf_engine.weights,
        "thresholds": mf_engine.factor_thresholds
    }


@router.post("/multi-factor/calculate")
async def calculate_fused_confidence(
    voice_confidence: float = Query(..., ge=0, le=1, description="Voice biometric confidence"),
    behavioral_confidence: float = Query(..., ge=0, le=1, description="Behavioral pattern confidence"),
    context_confidence: float = Query(..., ge=0, le=1, description="Context confidence"),
    proximity_confidence: float = Query(default=0.0, ge=0, le=1, description="Device proximity confidence"),
    history_confidence: float = Query(default=0.5, ge=0, le=1, description="Historical pattern confidence")
):
    """Calculate fused confidence from individual factors."""
    mf_engine = await get_multi_factor_engine()
    if not mf_engine:
        raise HTTPException(status_code=503, detail="Multi-factor engine not available")

    weights = mf_engine.weights

    fused = (
        voice_confidence * weights["voice"] +
        behavioral_confidence * weights["behavioral"] +
        context_confidence * weights["context"] +
        proximity_confidence * weights["proximity"] +
        history_confidence * weights["history"]
    )

    # Determine decision
    thresholds = mf_engine.factor_thresholds

    if voice_confidence < thresholds["voice"] and behavioral_confidence < 0.90:
        decision = "denied"
        reason = "Voice confidence below minimum threshold"
    elif fused >= thresholds["overall"]:
        decision = "authenticated"
        reason = "Fused confidence meets threshold"
    elif voice_confidence < 0.70 and behavioral_confidence >= 0.90:
        decision = "challenge_required"
        reason = "Low voice but high behavioral - challenge question needed"
    elif fused >= thresholds["challenge_trigger"]:
        decision = "challenge_required"
        reason = "Borderline confidence - challenge question needed"
    else:
        decision = "denied"
        reason = "Fused confidence below threshold"

    return {
        "success": True,
        "fused_confidence": round(fused, 4),
        "decision": decision,
        "reason": reason,
        "factors": {
            "voice": {"confidence": voice_confidence, "weight": weights["voice"]},
            "behavioral": {"confidence": behavioral_confidence, "weight": weights["behavioral"]},
            "context": {"confidence": context_confidence, "weight": weights["context"]},
            "proximity": {"confidence": proximity_confidence, "weight": weights["proximity"]},
            "history": {"confidence": history_confidence, "weight": weights["history"]}
        },
        "thresholds": thresholds
    }


# ============================================================================
# Feedback Generator Endpoints
# ============================================================================

@router.post("/feedback/generate")
async def generate_feedback(
    confidence: float = Query(..., ge=0, le=1, description="Authentication confidence"),
    snr_db: float = Query(default=18.0, description="Signal-to-noise ratio in dB"),
    hour: int = Query(default=12, ge=0, le=23, description="Hour of day (0-23)"),
    voice_changed: bool = Query(default=False, description="Voice anomaly detected"),
    new_location: bool = Query(default=False, description="New environment detected")
):
    """Generate voice feedback message based on authentication result."""
    feedback_gen = await get_feedback_generator()
    if not feedback_gen:
        raise HTTPException(status_code=503, detail="Feedback generator not available")

    context = {
        "snr_db": snr_db,
        "hour": hour,
        "voice_changed": voice_changed,
        "new_location": new_location
    }

    feedback = feedback_gen.generate_feedback(confidence, context)

    return {
        "success": True,
        "confidence_level": feedback.confidence_level.value,
        "message": feedback.message,
        "suggestion": feedback.suggestion,
        "is_final": feedback.is_final,
        "speak_aloud": feedback.speak_aloud
    }


@router.post("/feedback/security-alert")
async def generate_security_alert(
    threat_type: str = Query(..., description="Threat type: 'replay_attack', 'voice_cloning', 'synthetic_voice', 'unknown_speaker', 'environmental_anomaly'")
):
    """Generate security alert feedback for detected threats."""
    feedback_gen = await get_feedback_generator()
    if not feedback_gen:
        raise HTTPException(status_code=503, detail="Feedback generator not available")

    from voice.speaker_verification_service import ThreatType

    threat_map = {
        "replay_attack": ThreatType.REPLAY_ATTACK,
        "voice_cloning": ThreatType.VOICE_CLONING,
        "synthetic_voice": ThreatType.SYNTHETIC_VOICE,
        "unknown_speaker": ThreatType.UNKNOWN_SPEAKER,
        "environmental_anomaly": ThreatType.ENVIRONMENTAL_ANOMALY
    }

    if threat_type not in threat_map:
        raise HTTPException(
            status_code=400,
            detail=f"Unknown threat type. Available: {list(threat_map.keys())}"
        )

    feedback = feedback_gen.generate_security_alert(threat_map[threat_type])

    return {
        "success": True,
        "threat_type": threat_type,
        "confidence_level": feedback.confidence_level.value,
        "message": feedback.message,
        "suggestion": feedback.suggestion,
        "is_final": feedback.is_final,
        "speak_aloud": feedback.speak_aloud
    }


# ============================================================================
# Integration Test Endpoints
# ============================================================================

@router.post("/test/full-pipeline")
async def test_full_pipeline(
    speaker_name: str = Query(default="Derek", description="Speaker name"),
    simulate_success: bool = Query(default=True, description="Simulate successful auth")
):
    """
    Test the full authentication pipeline with all components.

    This endpoint:
    1. Starts a Langfuse audit session
    2. Simulates voice capture and analysis
    3. Checks ChromaDB for patterns
    4. Applies multi-factor fusion
    5. Generates appropriate feedback
    6. Ends the audit session

    Useful for end-to-end integration testing.
    """
    start_time = time.time()
    results = {
        "timestamp": datetime.utcnow().isoformat(),
        "speaker_name": speaker_name,
        "steps": []
    }

    # Step 1: Start audit session
    audit_trail = await get_audit_trail()
    session_id = None
    if audit_trail:
        session_id = audit_trail.start_session(speaker_name, "integration_test")
        results["steps"].append({
            "step": "audit_session_start",
            "success": True,
            "session_id": session_id
        })
    else:
        results["steps"].append({
            "step": "audit_session_start",
            "success": False,
            "reason": "Langfuse not available"
        })

    # Step 2: Simulate voice analysis
    voice_conf = 0.92 if simulate_success else 0.45
    behavioral_conf = 0.95 if simulate_success else 0.30
    results["steps"].append({
        "step": "voice_analysis",
        "success": True,
        "voice_confidence": voice_conf,
        "behavioral_confidence": behavioral_conf
    })

    # Step 3: Check ChromaDB patterns
    pattern_store = await get_pattern_store()
    if pattern_store and pattern_store._initialized:
        pattern_count = pattern_store._collection.count() if pattern_store._collection else 0
        results["steps"].append({
            "step": "chromadb_check",
            "success": True,
            "patterns_available": pattern_count
        })
    else:
        results["steps"].append({
            "step": "chromadb_check",
            "success": False,
            "reason": "ChromaDB not initialized"
        })

    # Step 4: Multi-factor fusion
    mf_engine = await get_multi_factor_engine()
    if mf_engine:
        fused = (
            voice_conf * mf_engine.weights["voice"] +
            behavioral_conf * mf_engine.weights["behavioral"] +
            0.95 * mf_engine.weights["context"] +
            0.0 * mf_engine.weights["proximity"] +
            0.5 * mf_engine.weights["history"]
        )
        authenticated = fused >= mf_engine.factor_thresholds["overall"]
        results["steps"].append({
            "step": "multi_factor_fusion",
            "success": True,
            "fused_confidence": round(fused, 3),
            "authenticated": authenticated
        })
    else:
        results["steps"].append({
            "step": "multi_factor_fusion",
            "success": False,
            "reason": "Multi-factor engine not available"
        })

    # Step 5: Generate feedback
    feedback_gen = await get_feedback_generator()
    if feedback_gen:
        feedback = feedback_gen.generate_feedback(fused if mf_engine else voice_conf)
        results["steps"].append({
            "step": "feedback_generation",
            "success": True,
            "message": feedback.message,
            "confidence_level": feedback.confidence_level.value
        })
    else:
        results["steps"].append({
            "step": "feedback_generation",
            "success": False,
            "reason": "Feedback generator not available"
        })

    # Step 6: End audit session
    if audit_trail and session_id:
        outcome = "authenticated" if (mf_engine and authenticated) else "denied"
        summary = audit_trail.end_session(session_id, outcome)
        results["steps"].append({
            "step": "audit_session_end",
            "success": True,
            "outcome": outcome
        })

    # Calculate overall result
    results["processing_time_ms"] = (time.time() - start_time) * 1000
    results["overall_success"] = all(s.get("success", False) for s in results["steps"])
    results["authenticated"] = mf_engine and authenticated if mf_engine else simulate_success

    return results


@router.get("/test/component-health")
async def test_component_health():
    """
    Quick test of all component initialization.

    Returns pass/fail status for each component.
    """
    results = {
        "timestamp": datetime.utcnow().isoformat(),
        "components": {}
    }

    # Test each component
    tests = [
        ("speaker_service", get_speaker_service),
        ("audit_trail", get_audit_trail),
        ("pattern_store", get_pattern_store),
        ("voice_cache", get_voice_cache),
        ("feedback_generator", get_feedback_generator),
        ("multi_factor_engine", get_multi_factor_engine)
    ]

    for name, getter in tests:
        try:
            instance = await getter()
            results["components"][name] = {
                "status": "pass" if instance else "warn",
                "initialized": instance is not None
            }
        except Exception as e:
            results["components"][name] = {
                "status": "fail",
                "error": str(e)
            }

    # Overall status
    statuses = [c["status"] for c in results["components"].values()]
    if all(s == "pass" for s in statuses):
        results["overall"] = "healthy"
    elif "fail" in statuses:
        results["overall"] = "unhealthy"
    else:
        results["overall"] = "degraded"

    return results
