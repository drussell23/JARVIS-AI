"""
Unified Command Processor - Dynamic command interpretation with zero hardcoding
Learns from the system and adapts to any environment
"""

import logging
from typing import Dict, Any, Optional, List, Tuple
from dataclasses import dataclass
from enum import Enum
import asyncio
from datetime import datetime
import json
from pathlib import Path
import re
from collections import defaultdict

logger = logging.getLogger(__name__)

# Import manual unlock handler
try:
    from api.manual_unlock_handler import handle_manual_unlock
except ImportError:
    handle_manual_unlock = None
    logger.warning("Manual unlock handler not available")


class DynamicPatternLearner:
    """Learns command patterns from usage and system analysis"""

    def __init__(self):
        self.learned_patterns = defaultdict(list)
        self.app_verbs = set()
        self.system_verbs = set()
        self.query_indicators = set()
        self.learned_apps = set()
        self.pattern_confidence = defaultdict(float)
        self._initialize_base_patterns()
        self._learn_from_system()

    def _initialize_base_patterns(self):
        """Initialize with minimal base patterns that will be expanded"""
        # These are just seeds - the system will learn more
        self.app_verbs = {"open", "close", "launch", "quit", "start", "kill"}
        self.system_verbs = {"set", "adjust", "toggle", "take", "enable", "disable"}
        self.query_indicators = {
            "what",
            "who",
            "where",
            "when",
            "why",
            "how",
            "is",
            "are",
            "can",
        }

    def _learn_from_system(self):
        """Learn available applications and commands from the system"""
        try:
            # Dynamically discover installed applications
            from system_control.dynamic_app_controller import get_dynamic_app_controller

            controller = get_dynamic_app_controller()

            # Learn all installed apps
            if hasattr(controller, "installed_apps_cache"):
                for app_key, app_info in controller.installed_apps_cache.items():
                    self.learned_apps.add(app_info["name"].lower())
                    # Also learn variations
                    self.learned_apps.add(app_key.lower())

            logger.info(f"Learned {len(self.learned_apps)} applications from system")

        except Exception as e:
            logger.debug(f"Could not learn from system controller: {e}")

    def learn_pattern(self, command: str, command_type: str, success: bool):
        """Learn from command execution results"""
        words = command.lower().split()
        if success and len(words) > 0:
            # Learn verb patterns
            first_word = words[0]
            if command_type == "system" and first_word not in self.system_verbs:
                self.system_verbs.add(first_word)
                self.pattern_confidence[f"verb_{first_word}"] += 0.1

            # Learn app names from successful commands
            if command_type == "system" and any(
                verb in words for verb in self.app_verbs
            ):
                # Extract potential app names
                for i, word in enumerate(words):
                    if word in self.app_verbs and i + 1 < len(words):
                        potential_app = words[i + 1]
                        if (
                            potential_app not in self.app_verbs
                            and potential_app not in self.system_verbs
                        ):
                            self.learned_apps.add(potential_app)

    def is_learned_app(self, word: str) -> bool:
        """Check if a word is a learned app name"""
        return word.lower() in self.learned_apps

    def get_command_patterns(self, command_type: str) -> List[str]:
        """Get learned patterns for a command type"""
        return self.learned_patterns.get(command_type, [])


class CommandType(Enum):
    """Types of commands JARVIS can handle"""

    VISION = "vision"
    SYSTEM = "system"
    WEATHER = "weather"
    COMMUNICATION = "communication"
    AUTONOMY = "autonomy"
    QUERY = "query"
    COMPOUND = "compound"
    META = "meta"
    VOICE_UNLOCK = "voice_unlock"
    DOCUMENT = "document"
    UNKNOWN = "unknown"


@dataclass
class UnifiedContext:
    """Single context shared across all command processing"""

    conversation_history: List[Dict[str, Any]]
    current_visual: Optional[Dict[str, Any]] = None
    last_entity: Optional[Dict[str, Any]] = None  # For "it/that" resolution
    active_monitoring: bool = False
    user_preferences: Optional[Dict[str, Any]] = None
    system_state: Optional[Dict[str, Any]] = None

    def __post_init__(self):
        if self.user_preferences is None:
            self.user_preferences = {}
        if self.system_state is None:
            self.system_state = {}

    def resolve_reference(self, text: str) -> Tuple[Optional[str], float]:
        """Resolve 'it', 'that', 'this' to actual entities"""
        reference_words = ["it", "that", "this", "them"]

        for word in reference_words:
            if word in text.lower():
                if self.last_entity:
                    # Check how recent the entity is
                    if "timestamp" in self.last_entity:
                        age = (datetime.now() - self.last_entity["timestamp"]).seconds
                        confidence = 0.9 if age < 30 else 0.7 if age < 60 else 0.5
                    else:
                        confidence = 0.8
                    return self.last_entity.get("value", ""), confidence

                # Check visual context
                if self.current_visual:
                    return self.current_visual.get("focused_element", ""), 0.7

        return None, 0.0

    def update_from_command(self, command_type: CommandType, result: Dict[str, Any]):
        """Update context based on command execution"""
        self.conversation_history.append(
            {"type": command_type.value, "result": result, "timestamp": datetime.now()}
        )

        # Extract entities for future reference
        if command_type == CommandType.VISION and "elements" in result:
            if result["elements"]:
                self.last_entity = {
                    "value": result["elements"][0],
                    "timestamp": datetime.now(),
                    "type": "visual_element",
                }

        # Update visual context
        if command_type == CommandType.VISION:
            self.current_visual = result.get("visual_context", {})


class UnifiedCommandProcessor:
    """Dynamic command processor that learns and adapts"""

    def __init__(self, claude_api_key: Optional[str] = None):
        self.context = UnifiedContext(conversation_history=[])
        self.handlers = {}
        self.pattern_learner = DynamicPatternLearner()
        self.command_stats = defaultdict(int)
        self.success_patterns = defaultdict(list)
        self._initialize_handlers()
        self.claude_api_key = claude_api_key
        self._load_learned_data()

    def _load_learned_data(self):
        """Load previously learned patterns and statistics"""
        try:
            data_dir = Path.home() / ".jarvis" / "learning"
            data_dir.mkdir(parents=True, exist_ok=True)

            stats_file = data_dir / "command_stats.json"
            if stats_file.exists():
                with open(stats_file, "r") as f:
                    self.command_stats = defaultdict(int, json.load(f))

            patterns_file = data_dir / "success_patterns.json"
            if patterns_file.exists():
                with open(patterns_file, "r") as f:
                    self.success_patterns = defaultdict(list, json.load(f))

        except Exception as e:
            logger.debug(f"Could not load learned data: {e}")

    def _save_learned_data(self):
        """Save learned patterns and statistics"""
        try:
            data_dir = Path.home() / ".jarvis" / "learning"
            data_dir.mkdir(parents=True, exist_ok=True)

            with open(data_dir / "command_stats.json", "w") as f:
                json.dump(dict(self.command_stats), f)

            with open(data_dir / "success_patterns.json", "w") as f:
                json.dump(dict(self.success_patterns), f)

        except Exception as e:
            logger.debug(f"Could not save learned data: {e}")

    def _initialize_handlers(self):
        """Initialize command handlers lazily"""
        # We'll import handlers only when needed to avoid circular imports
        self.handler_modules = {
            CommandType.VISION: "api.vision_command_handler",
            CommandType.SYSTEM: "system_control.macos_controller",
            CommandType.WEATHER: "system_control.weather_system_config",
            CommandType.AUTONOMY: "api.autonomy_handler",
            CommandType.VOICE_UNLOCK: "api.voice_unlock_handler",
            CommandType.QUERY: "api.query_handler",  # Add basic query handler
        }

    async def process_command(
        self, command_text: str, websocket=None
    ) -> Dict[str, Any]:
        """Process any command through unified pipeline with FULL context awareness"""
        logger.info(f"[UNIFIED] Processing with context awareness: '{command_text}'")

        # Track command frequency
        self.command_stats[command_text.lower()] += 1

        # NEW: Get context-aware handler for ALL commands
        from context_intelligence.handlers.context_aware_handler import (
            get_context_aware_handler,
        )

        context_handler = get_context_aware_handler()

        # Step 1: Classify command intent
        command_type, confidence = await self._classify_command(command_text)
        logger.info(
            f"[UNIFIED] Classified as {command_type.value} (confidence: {confidence})"
        )

        # Step 2: Check system context FIRST (screen lock, active apps, etc.)
        system_context = await self._get_full_system_context()
        logger.info(
            f"[UNIFIED] System context: screen_locked={system_context.get('screen_locked')}, active_apps={len(system_context.get('active_apps', []))}"
        )

        # Step 3: Resolve references with context
        resolved_text = command_text
        reference, ref_confidence = self.context.resolve_reference(command_text)
        if reference and ref_confidence > 0.5:
            # Replace reference with resolved entity
            for word in ["it", "that", "this"]:
                if word in command_text.lower():
                    resolved_text = command_text.lower().replace(word, reference)
                    logger.info(f"[UNIFIED] Resolved '{word}' to '{reference}'")
                    break

        # Step 4: Define command execution callback
        async def execute_with_context(cmd: str, context: Dict[str, Any] = None):
            """Execute command with full context awareness"""
            if command_type == CommandType.COMPOUND:
                return await self._handle_compound_command(cmd, context=context)
            else:
                return await self._execute_command(
                    command_type, cmd, websocket, context=context
                )

        # Step 5: Process through context-aware handler
        logger.info(f"[UNIFIED] Processing through context-aware handler...")
        result = await context_handler.handle_command_with_context(
            resolved_text, execute_callback=execute_with_context
        )

        # Step 6: Extract actual result from context handler response
        if result.get("result"):
            # Use the nested result from context handler
            actual_result = result["result"]
        else:
            # Fallback to the full result
            actual_result = result

        # Step 7: Learn from the result
        if actual_result.get("success", False):
            self.pattern_learner.learn_pattern(command_text, command_type.value, True)
            self.success_patterns[command_type.value].append(
                {
                    "command": command_text,
                    "timestamp": datetime.now().isoformat(),
                    "context": system_context,  # Store context for learning
                }
            )
            # Keep only recent patterns
            if len(self.success_patterns[command_type.value]) > 100:
                self.success_patterns[command_type.value] = self.success_patterns[
                    command_type.value
                ][-100:]

        # Step 8: Update context with result
        self.context.update_from_command(command_type, actual_result)
        self.context.system_state = system_context  # Update system state

        # Save learned data periodically (every 10 commands)
        if sum(self.command_stats.values()) % 10 == 0:
            self._save_learned_data()

        # Return the formatted result
        return {
            "success": actual_result.get("success", False),
            "response": result.get("summary", actual_result.get("response", "")),
            "command_type": command_type.value,
            "context_aware": True,
            "system_context": system_context,
            **actual_result,
        }

    async def _classify_command(self, command_text: str) -> Tuple[CommandType, float]:
        """Dynamically classify command using learned patterns"""
        command_lower = command_text.lower().strip()
        words = command_lower.split()

        # Manual screen lock/unlock detection (HIGHEST PRIORITY - check first!)
        # Check for exact matches first
        if command_lower in [
            "unlock my screen",
            "unlock screen",
            "unlock the screen",
            "lock my screen",
            "lock screen",
            "lock the screen",
        ]:
            logger.info(
                f"[CLASSIFY] Manual screen lock/unlock command detected: '{command_lower}'"
            )
            return (
                CommandType.VOICE_UNLOCK,
                0.99,
            )  # Route to voice unlock handler with high confidence

        # Voice unlock detection FIRST (highest priority to catch "enable voice unlock")
        voice_patterns = self._detect_voice_unlock_patterns(command_lower)
        if voice_patterns > 0:
            logger.info(
                f"Voice unlock command detected: '{command_lower}' with patterns={voice_patterns}"
            )
            return CommandType.VOICE_UNLOCK, 0.85 + (voice_patterns * 0.05)

        # Check for implicit compound commands (app + action without connector)
        # Example: "open safari search for cats"
        if len(words) >= 3:
            # Look for patterns like "verb app verb"
            potential_app_indices = []
            for i, word in enumerate(words):
                if self.pattern_learner.is_learned_app(word):
                    potential_app_indices.append(i)

            # Check if there are verbs before and after an app name
            for app_idx in potential_app_indices:
                if app_idx > 0 and app_idx < len(words) - 1:
                    # Check if word before app is a verb
                    before_verb = words[app_idx - 1] in self.pattern_learner.app_verbs
                    # Check if there's a verb or action after the app
                    after_has_action = any(
                        word
                        in self.pattern_learner.app_verbs
                        | {"search", "navigate", "go", "type"}
                        for word in words[app_idx + 1 :]
                    )

                    if before_verb and after_has_action:
                        # This is an implicit compound command
                        logger.info(
                            f"[CLASSIFY] Detected implicit compound: verb-app-action pattern"
                        )
                        return CommandType.COMPOUND, 0.9

        # Dynamic compound detection - learn from connectors
        compound_indicators = {" and ", " then ", ", and ", ", then ", " && ", " ; "}
        for indicator in compound_indicators:
            if indicator in command_lower:
                # Check if this is truly compound by analyzing both sides
                parts = command_lower.split(indicator)
                if len(parts) >= 2 and all(len(p.strip()) > 0 for p in parts):
                    # Both sides have content - likely compound
                    # But exclude if it's part of a single concept
                    if not self._is_single_concept(command_lower, indicator):
                        return CommandType.COMPOUND, 0.95

        # Dynamic system command detection using learned patterns
        first_word = words[0] if words else ""

        # Check if first word is a learned verb
        if (
            first_word in self.pattern_learner.app_verbs
            or first_word in self.pattern_learner.system_verbs
        ):
            # Check if any word is a learned app
            for word in words[1:]:
                if self.pattern_learner.is_learned_app(word):
                    return CommandType.SYSTEM, 0.9

            # Check for system settings patterns
            system_indicators = self._detect_system_indicators(words)
            if system_indicators > 0:
                return CommandType.SYSTEM, 0.85 + (system_indicators * 0.05)

        # Dynamic app detection - if any learned app is mentioned
        mentioned_apps = [
            word for word in words if self.pattern_learner.is_learned_app(word)
        ]
        if mentioned_apps:
            # Check for action context
            has_action = any(word in self.pattern_learner.app_verbs for word in words)
            if has_action:
                return CommandType.SYSTEM, 0.9

        # Document creation detection (high priority - before vision)
        # Use root words that will match variations (write/writing/writes, create/creating, etc.)
        document_keywords = [
            "writ",
            "creat",
            "draft",
            "compos",
            "generat",
        ]  # Root forms
        document_types = [
            "essay",
            "report",
            "paper",
            "article",
            "document",
            "blog",
            "letter",
            "story",
        ]

        # Check if any word starts with a document keyword (handles write/writing/writes, etc.)
        has_document_keyword = any(
            any(word.startswith(kw) for word in words) for kw in document_keywords
        )
        has_document_type = any(dtype in words for dtype in document_types)

        if has_document_keyword and has_document_type:
            logger.info(
                f"[CLASSIFY] Document creation command detected: '{command_text}'"
            )
            return CommandType.DOCUMENT, 0.95

        # Vision detection through semantic analysis
        vision_score = self._calculate_vision_score(words, command_lower)
        if vision_score > 0.7:
            return CommandType.VISION, vision_score

        # Weather detection - simple but effective
        if "weather" in words:
            return CommandType.WEATHER, 0.95

        # Autonomy detection
        autonomy_score = self._calculate_autonomy_score(words)
        if autonomy_score > 0.7:
            return CommandType.AUTONOMY, autonomy_score

        # Meta command detection
        meta_indicators = {"cancel", "stop", "undo", "never", "not", "wait", "hold"}
        meta_count = sum(1 for word in words if word in meta_indicators)
        if meta_count > 0 and len(words) < 5:
            return CommandType.META, 0.8 + (meta_count * 0.05)

        # Wake word detection
        if command_lower.strip() in {
            "hey",
            "hi",
            "hello",
            "jarvis",
            "hey jarvis",
            "activate",
            "wake",
            "wake up",
        }:
            return CommandType.META, 0.9

        # Query detection through linguistic analysis
        is_question = self._is_question_pattern(words)
        if is_question:
            return CommandType.QUERY, 0.8

        # URL/Web detection
        if self._contains_url_pattern(command_lower):
            return CommandType.SYSTEM, 0.85

        # Navigation patterns
        nav_patterns = {"go", "navigate", "browse", "visit", "open", "search"}
        if any(word in words for word in nav_patterns) and len(words) > 1:
            return CommandType.SYSTEM, 0.75

        # Short commands default to system if they contain verbs
        if len(words) <= 3 and any(
            word in self.pattern_learner.app_verbs | self.pattern_learner.system_verbs
            for word in words
        ):
            return CommandType.SYSTEM, 0.7

        # Default to query with lower confidence
        return CommandType.QUERY, 0.5

    def _is_single_concept(self, text: str, connector: str) -> bool:
        """Check if connector is part of a single concept rather than joining commands"""
        # Common phrases that shouldn't be split
        single_concepts = {
            "and press enter",
            "and enter",
            "and return",
            "black and white",
            "up and down",
            "back and forth",
            "pros and cons",
            "dos and don'ts",
        }

        for concept in single_concepts:
            if concept in text:
                return True

        # Check if it's part of a search query or typed text
        before_connector = text.split(connector)[0]
        if any(
            pattern in before_connector
            for pattern in ["search for", "type", "write", "enter"]
        ):
            return True

        return False

    def _detect_system_indicators(self, words: List[str]) -> int:
        """Count system-related indicators in words"""
        indicators = 0

        # System settings
        settings_words = {
            "volume",
            "brightness",
            "wifi",
            "bluetooth",
            "display",
            "sound",
            "network",
        }
        indicators += sum(1 for word in words if word in settings_words)

        # System actions
        action_words = {"screenshot", "restart", "shutdown", "sleep", "lock", "unlock"}
        indicators += sum(1 for word in words if word in action_words)

        # File operations
        file_words = {
            "file",
            "folder",
            "directory",
            "document",
            "save",
            "open",
            "create",
        }
        indicators += sum(1 for word in words if word in file_words)

        return indicators

    def _calculate_vision_score(self, words: List[str], command_lower: str) -> float:
        """Calculate likelihood of vision command"""
        score = 0.0

        # EXCLUDE lock/unlock commands - they're system commands, not vision
        if "lock" in words or "unlock" in words:
            return 0.0

        # Vision verbs
        vision_verbs = {
            "see",
            "look",
            "watch",
            "monitor",
            "analyze",
            "describe",
            "show",
            "read",
            "check",
            "examine",
        }
        score += sum(0.2 for word in words if word in vision_verbs)

        # Vision nouns (but be careful with 'screen' - it could be system related)
        vision_nouns = {
            "display",
            "window",
            "image",
            "visual",
            "picture",
            "desktop",
            "space",
            "workspace",
            "screen",
        }
        score += sum(0.15 for word in words if word in vision_nouns)

        # Multi-space indicators (very strong vision signal)
        multi_space_indicators = {
            "desktop",
            "space",
            "workspace",
            "across",
            "multiple",
            "different",
            "other",
            "all",
        }
        multi_space_count = sum(1 for word in words if word in multi_space_indicators)
        if multi_space_count > 0:
            score += 0.4 * multi_space_count  # Strong boost for multi-space queries

        # 'screen' only counts as vision if paired with vision verbs or multi-space indicators
        if "screen" in words and (
            any(word in vision_verbs for word in words) or multi_space_count > 0
        ):
            score += 0.15

        # Questioning about visual or workspace
        if words and words[0] in {"what", "what's", "whats"}:
            visual_indicators = {
                "screen",
                "see",
                "display",
                "desktop",
                "space",
                "workspace",
                "happening",
                "going",
                "doing",
            }
            if any(word in words for word in visual_indicators):
                score += 0.3

        # Phrases that strongly indicate workspace/multi-space vision queries
        workspace_phrases = [
            "desktop space",
            "across my desktop",
            "multiple desktop",
            "different space",
            "what am i working",
            "what is happening",
            "what is going on",
        ]
        for phrase in workspace_phrases:
            if phrase in command_lower:
                score += 0.5

        return min(score, 0.95)

    def _detect_voice_unlock_patterns(self, text: str) -> int:
        """Detect voice unlock related patterns"""
        patterns = 0

        voice_words = {"voice", "vocal", "speech", "voiceprint"}
        unlock_words = {
            "unlock",
            "lock",
            "authenticate",
            "verify",
            "enroll",
            "enrollment",
        }

        # Check for voice + unlock combinations
        has_voice = any(word in text for word in voice_words)
        has_unlock = any(word in text for word in unlock_words)

        if has_voice and has_unlock:
            patterns += 2
        elif has_voice or has_unlock:
            patterns += 1

        # Log for debugging
        if has_voice or has_unlock:
            logger.debug(
                f"Voice unlock pattern detection: text='{text}', has_voice={has_voice}, has_unlock={has_unlock}, patterns={patterns}"
            )

        # Direct phrases - these are definitely voice unlock commands
        voice_unlock_phrases = [
            "voice unlock",
            "unlock with voice",
            "enable voice unlock",
            "disable voice unlock",
            "enroll my voice",
            "enroll voice",
            "voice enrollment",
        ]

        if any(phrase in text for phrase in voice_unlock_phrases):
            patterns += 3  # Strong match

        return patterns

    def _calculate_autonomy_score(self, words: List[str]) -> float:
        """Calculate autonomy command likelihood"""
        score = 0.0

        autonomy_words = {"autonomy", "autonomous", "auto", "automatic", "self"}
        control_words = {"control", "take", "activate", "enable", "mode"}

        score += sum(0.3 for word in words if word in autonomy_words)
        score += sum(0.2 for word in words if word in control_words)

        # Boost for specific phrases
        text = " ".join(words)
        if "take over" in text or "full control" in text:
            score += 0.4

        return min(score, 0.95)

    def _is_question_pattern(self, words: List[str]) -> bool:
        """Detect if command is a question"""
        if not words:
            return False

        # Question starters
        question_starts = {
            "what",
            "who",
            "where",
            "when",
            "why",
            "how",
            "is",
            "are",
            "can",
            "could",
            "would",
            "should",
            "will",
            "do",
            "does",
        }

        # Check first word
        if words[0] in question_starts:
            return True

        # Check for question marks (though unlikely in voice)
        if any("?" in word for word in words):
            return True

        return False

    def _contains_url_pattern(self, text: str) -> bool:
        """Check if text contains URL patterns"""
        # URL indicators
        url_patterns = [
            r"https?://",
            r"www\.",
            r"\.(com|org|net|edu|gov|io|co|uk)",
            r"://",
        ]

        for pattern in url_patterns:
            if re.search(pattern, text):
                return True

        # Common websites without full URLs
        websites = {
            "google",
            "facebook",
            "twitter",
            "youtube",
            "github",
            "amazon",
            "reddit",
        }
        words = text.split()

        # Check if website is mentioned with navigation verb
        nav_verbs = {"go", "visit", "open", "navigate", "browse"}
        for i, word in enumerate(words):
            if word in websites and i > 0 and words[i - 1] in nav_verbs:
                return True

        return False

    async def _get_full_system_context(self) -> Dict[str, Any]:
        """Get comprehensive system context for intelligent command processing"""
        try:
            from context_intelligence.detectors.screen_lock_detector import (
                get_screen_lock_detector,
            )

            screen_detector = get_screen_lock_detector()
            is_locked = await screen_detector.is_screen_locked()

            # Get active applications (you can expand this)
            active_apps = []
            try:
                import subprocess

                result = subprocess.run(
                    [
                        "osascript",
                        "-e",
                        'tell application "System Events" to get name of (processes where background only is false)',
                    ],
                    capture_output=True,
                    text=True,
                    timeout=2,
                )
                if result.returncode == 0:
                    active_apps = result.stdout.strip().split(", ")
            except:
                pass

            return {
                "screen_locked": is_locked,
                "active_apps": active_apps,
                "network_connected": True,  # You can expand this check
                "timestamp": datetime.now().isoformat(),
                "user_preferences": self.context.user_preferences,
                "conversation_history": len(self.context.conversation_history),
            }
        except Exception as e:
            logger.warning(f"Could not get full system context: {e}")
            return {
                "screen_locked": False,
                "active_apps": [],
                "network_connected": True,
                "timestamp": datetime.now().isoformat(),
            }

    async def _execute_command(
        self,
        command_type: CommandType,
        command_text: str,
        websocket=None,
        context: Dict[str, Any] = None,
    ) -> Dict[str, Any]:
        """Execute command using appropriate handler"""

        # Get or initialize handler
        if command_type not in self.handlers:
            handler = await self._get_handler(command_type)
            if handler:
                self.handlers[command_type] = handler

        handler = self.handlers.get(command_type)

        if not handler and command_type not in [
            CommandType.SYSTEM,
            CommandType.META,
            CommandType.DOCUMENT,
        ]:
            return {
                "success": False,
                "response": f"I don't have a handler for {command_type.value} commands yet.",
                "command_type": command_type.value,
            }

        # Execute with unified context
        try:
            # Different handlers have different interfaces, normalize them
            if command_type == CommandType.VISION:
                # For vision commands, check if it's a monitoring command or analysis
                if any(
                    word in command_text.lower()
                    for word in ["start", "stop", "monitor"]
                ):
                    result = await handler.handle_command(command_text)
                else:
                    # It's a vision query - analyze the screen with the specific query
                    result = await handler.analyze_screen(command_text)

                return {
                    "success": result.get("handled", False),
                    "response": result.get("response", ""),
                    "command_type": command_type.value,
                    **result,
                }
            elif command_type == CommandType.WEATHER:
                result = await handler.get_weather(command_text)
                return {
                    "success": result.get("success", False),
                    "response": result.get(
                        "formatted_response", result.get("message", "")
                    ),
                    "command_type": command_type.value,
                    **result,
                }
            elif command_type == CommandType.SYSTEM:
                # Handle system commands (app control, system settings, etc.)
                result = await self._execute_system_command(command_text)
                return {
                    "success": result.get("success", False),
                    "response": result.get("response", ""),
                    "command_type": command_type.value,
                    **result,
                }
            elif command_type == CommandType.META:
                # Handle meta commands (wake words, cancellations)
                if command_text.lower().strip() in [
                    "activate",
                    "wake",
                    "wake up",
                    "hello",
                    "hey",
                ]:
                    # Silent acknowledgment for wake words
                    return {
                        "success": True,
                        "response": "",
                        "command_type": "meta",
                        "silent": True,
                    }
                else:
                    return {
                        "success": True,
                        "response": "Understood",
                        "command_type": "meta",
                    }
            elif command_type == CommandType.DOCUMENT:
                # Handle document creation commands WITH CONTEXT AWARENESS
                logger.info(
                    f"[DOCUMENT] Routing to context-aware document handler: '{command_text}'"
                )
                try:
                    from context_intelligence.handlers.context_aware_handler import (
                        get_context_aware_handler,
                    )
                    from context_intelligence.executors import (
                        get_document_writer,
                        parse_document_request,
                    )

                    # Get the context-aware handler
                    context_handler = get_context_aware_handler()

                    # Define the document creation callback
                    async def create_document_callback(
                        command: str, context: Dict[str, Any] = None
                    ):
                        logger.info(
                            f"[DOCUMENT] Creating document within context-aware flow"
                        )

                        # Parse the document request
                        doc_request = parse_document_request(command, {})

                        # Get document writer
                        writer = get_document_writer()

                        # Start document creation as a background task (non-blocking)
                        # This allows us to return immediately with feedback
                        logger.info(
                            f"[DOCUMENT] Starting background document creation task"
                        )
                        asyncio.create_task(
                            writer.create_document(
                                request=doc_request, websocket=websocket
                            )
                        )

                        # Return immediate feedback to user
                        return {
                            "success": True,
                            "task_started": True,
                            "topic": doc_request.topic,
                            "message": f"I'm creating an essay about {doc_request.topic} for you, Sir.",
                        }

                    # Use context-aware handler to check screen lock FIRST
                    logger.info(
                        f"[DOCUMENT] Checking context (including screen lock) before document creation..."
                    )
                    result = await context_handler.handle_command_with_context(
                        command_text, execute_callback=create_document_callback
                    )

                    # The context handler will handle all messaging including screen lock notifications
                    if result.get("success"):
                        return {
                            "success": True,
                            "response": result.get(
                                "summary",
                                result.get("messages", ["Document created"])[0],
                            ),
                            "command_type": command_type.value,
                            "speak": False,  # Context handler already spoke if needed
                            **result,
                        }
                    else:
                        return {
                            "success": False,
                            "response": result.get(
                                "summary",
                                result.get("messages", ["Failed to create document"])[
                                    0
                                ],
                            ),
                            "command_type": command_type.value,
                            **result,
                        }

                except Exception as e:
                    logger.error(
                        f"[DOCUMENT] Error in context-aware document creation: {e}",
                        exc_info=True,
                    )
                    return {
                        "success": False,
                        "response": f"I encountered an error creating the document: {str(e)}",
                        "command_type": command_type.value,
                        "error": str(e),
                    }
            elif command_type == CommandType.VOICE_UNLOCK:
                # Handle voice unlock commands with quick response
                command_lower = command_text.lower()

                # Check for initial enrollment request
                if (
                    "enroll" in command_lower
                    and "voice" in command_lower
                    and "start" not in command_lower
                ):
                    # Quick response for enrollment instructions
                    return {
                        "success": True,
                        "response": 'To enroll your voice, Sir, I need you to speak clearly for about 10 seconds. Say "Start voice enrollment now" when you are ready in a quiet environment.',
                        "command_type": command_type.value,
                        "type": "voice_unlock",
                        "action": "enrollment_instructions",
                        "next_command": "start voice enrollment now",
                    }
                # For actual enrollment start, let the handler process it
                elif any(
                    phrase in command_lower
                    for phrase in [
                        "start voice enrollment now",
                        "begin voice enrollment",
                        "start enrollment now",
                    ]
                ):
                    # Let the actual handler process enrollment
                    result = await handler.handle_command(command_text, websocket)
                    return {
                        "success": result.get(
                            "success", result.get("type") == "voice_unlock"
                        ),
                        "response": result.get("message", result.get("response", "")),
                        "command_type": command_type.value,
                        **result,
                    }
                else:
                    # Other voice unlock commands - use the handler
                    result = await handler.handle_command(command_text, websocket)
                    return {
                        "success": result.get(
                            "success", result.get("type") == "voice_unlock"
                        ),
                        "response": result.get("message", result.get("response", "")),
                        "command_type": command_type.value,
                        **result,
                    }
            else:
                # Generic handler interface
                return {
                    "success": True,
                    "response": f"Executing {command_type.value} command",
                    "command_type": command_type.value,
                }

        except Exception as e:
            logger.error(
                f"Error executing {command_type.value} command: {e}", exc_info=True
            )
            return {
                "success": False,
                "response": f"I encountered an error with that {command_type.value} command.",
                "command_type": command_type.value,
                "error": str(e),
            }

    async def _get_handler(self, command_type: CommandType):
        """Dynamically import and get handler for command type"""
        # System commands are handled directly in _execute_command
        if command_type == CommandType.SYSTEM:
            return True  # Return True to indicate system handler is available

        module_name = self.handler_modules.get(command_type)
        if not module_name:
            return None

        try:
            if command_type == CommandType.VISION:
                from api.vision_command_handler import vision_command_handler

                return vision_command_handler
            elif command_type == CommandType.WEATHER:
                from system_control.weather_system_config import get_weather_system

                return get_weather_system()
            elif command_type == CommandType.AUTONOMY:
                from api.autonomy_handler import get_autonomy_handler

                return get_autonomy_handler()
            elif command_type == CommandType.VOICE_UNLOCK:
                from api.voice_unlock_handler import get_voice_unlock_handler

                return get_voice_unlock_handler()
            # Add other handlers as needed

        except ImportError as e:
            logger.error(f"Failed to import handler for {command_type.value}: {e}")
            return None

    async def _handle_compound_command(
        self, command_text: str, context: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """Handle commands with multiple parts and maintain context between them"""
        logger.info(
            f"[COMPOUND] Handling compound command with context: {context is not None}"
        )

        # Parse compound commands more intelligently
        parts = self._parse_compound_parts(command_text)

        results = []
        all_success = True
        responses = []

        # Track context for dependent commands
        active_app = None
        previous_result = None

        # Use provided context if available
        if context:
            logger.info(f"[COMPOUND] Using provided system context")

        # Check if all parts are similar operations that can be parallelized
        can_parallelize = self._can_parallelize_commands(parts)

        if can_parallelize:
            # Process similar operations in parallel (e.g., closing multiple apps)
            logger.info(
                f"[COMPOUND] Processing {len(parts)} similar commands in parallel"
            )

            # Create tasks for parallel execution
            tasks = []
            for part in parts:
                part = part.strip()
                if not part:
                    continue

                # Process each part as an independent command
                async def process_part(p):
                    command_type, _ = await self._classify_command(p)
                    if command_type == CommandType.COMPOUND:
                        command_type = CommandType.SYSTEM
                    return await self._execute_command(command_type, p)

                tasks.append(process_part(part))

            # Execute all tasks in parallel
            results = await asyncio.gather(*tasks)

            # Collect responses
            for result in results:
                if result.get("success", False):
                    responses.append(result.get("response", ""))
                else:
                    all_success = False
                    responses.append(
                        f"Failed: {result.get('response', 'Unknown error')}"
                    )
        else:
            # Sequential processing for dependent commands
            for i, part in enumerate(parts):
                part = part.strip()
                if not part:
                    continue

                # Provide user feedback for multi-step commands
                if len(parts) > 1:
                    logger.info(f"[COMPOUND] Step {i+1}/{len(parts)}: {part}")

                # Check if this is a dependent command that needs context
                enhanced_command = self._enhance_with_context(
                    part, active_app, previous_result
                )
                logger.info(
                    f"[COMPOUND] Enhanced command: '{part}' -> '{enhanced_command}' (active_app: {active_app})"
                )

                # Process individual part (not as compound to avoid recursion)
                command_type, _ = await self._classify_command(enhanced_command)
                # Force non-compound to avoid recursion
                if command_type == CommandType.COMPOUND:
                    command_type = CommandType.SYSTEM

                result = await self._execute_command(command_type, enhanced_command)
                results.append(result)

                # Update context for next command
                if result.get("success", False):
                    # Track opened apps for subsequent commands
                    if any(
                        word in part.lower() for word in ["open", "launch", "start"]
                    ):
                        # Find which app was opened dynamically
                        words = enhanced_command.lower().split()
                        for word in words:
                            if self.pattern_learner.is_learned_app(word):
                                active_app = word
                                # Even if app is already open, we want to track it for context
                                logger.info(
                                    f"[COMPOUND] Tracking active app: {active_app}"
                                )
                                break

                    # Skip "already open" messages in compound commands
                    response = result.get("response", "")
                    if "already open" not in response.lower() or len(parts) == 1:
                        responses.append(response)
                else:
                    all_success = False
                    responses.append(
                        f"Failed: {result.get('response', 'Unknown error')}"
                    )
                    # Don't continue if a step fails
                    break

                previous_result = result

                # Add small delay between commands for reliability
                if i < len(parts) - 1:
                    await asyncio.sleep(0.5)

        # Create conversational response
        if len(responses) > 1:
            # Clean up individual responses first
            cleaned_responses = []
            for i, resp in enumerate(responses):
                # Remove trailing "Sir" from all but the last response
                if resp.endswith(", Sir") and i < len(responses) - 1:
                    resp = resp[:-5]
                cleaned_responses.append(resp)

            # Combine into natural response
            if len(cleaned_responses) == 2:
                # For 2 steps: "Opening Safari and searching for dogs"
                response = f"{cleaned_responses[0]} and {cleaned_responses[1]}"
            else:
                # For 3+ steps: "Opening Safari, navigating to Google, and taking a screenshot"
                response = (
                    ", ".join(cleaned_responses[:-1]) + f" and {cleaned_responses[-1]}"
                )

            # Add "Sir" at the end if it's not already there
            if not response.endswith(", Sir"):
                response += ", Sir"
        else:
            response = responses[0] if responses else "I'll help you with that"

        return {
            "success": all_success,
            "response": response,
            "command_type": CommandType.COMPOUND.value,
            "sub_results": results,
            "steps_completed": len([r for r in results if r.get("success", False)]),
            "total_steps": len(parts),
            "context": context or {},
            "steps_taken": [f"Step {i+1}: {part}" for i, part in enumerate(parts)],
        }

    def _parse_compound_parts(self, command_text: str) -> List[str]:
        """Dynamically parse compound command into logical parts"""
        # Check for multi-operation patterns
        multi_op_patterns = [
            "separate tabs",
            "different tabs",
            "multiple tabs",
            "each tab",
            "respectively",
        ]
        if any(pattern in command_text.lower() for pattern in multi_op_patterns):
            # This is a single complex command with multiple targets
            return [command_text]

        # First check for implicit compound (no connector)
        words = command_text.lower().split()
        if len(words) >= 3:
            # Look for app names to find split points
            for i, word in enumerate(words):
                if (
                    self.pattern_learner.is_learned_app(word)
                    and i > 0
                    and i < len(words) - 1
                ):
                    # Check if there's a verb before and action after
                    if words[i - 1] in self.pattern_learner.app_verbs:
                        # Check if there's an action after the app
                        remaining_words = words[i + 1 :]
                        if any(
                            w
                            in self.pattern_learner.app_verbs
                            | {"search", "navigate", "go", "type"}
                            for w in remaining_words
                        ):
                            # Split at the app name
                            part1 = " ".join(words[: i + 1])
                            part2 = " ".join(words[i + 1 :])
                            logger.info(
                                f"[PARSE] Split implicit compound: '{part1}' | '{part2}'"
                            )
                            return [part1, part2]

        # Dynamic connector detection
        connectors = [
            " and ",
            " then ",
            ", and ",
            ", then ",
            " && ",
            " ; ",
            " plus ",
            " also ",
        ]

        # Smart parsing - analyze command structure
        parts = []
        remaining = command_text

        # Find all connector positions
        connector_positions = []
        for connector in connectors:
            pos = 0
            while connector in remaining[pos:]:
                index = remaining.find(connector, pos)
                if index != -1:
                    connector_positions.append((index, connector))
                    pos = index + 1
                else:
                    break

        # Sort by position
        connector_positions.sort(key=lambda x: x[0])

        if not connector_positions:
            return [command_text]

        # Analyze each potential split point
        last_pos = 0
        for pos, connector in connector_positions:
            before = remaining[last_pos:pos].strip()
            after = remaining[pos + len(connector) :].strip()

            # Use intelligent splitting logic
            should_split = self._should_split_at_connector(before, after, connector)

            if should_split:
                if before:
                    parts.append(before)
                last_pos = pos + len(connector)

        # Add remaining part
        final_part = remaining[last_pos:].strip()
        if final_part:
            parts.append(final_part)

        # If no valid splits, return original
        return parts if parts else [command_text]

    def _should_split_at_connector(
        self, before: str, after: str, connector: str
    ) -> bool:
        """Determine if we should split at this connector"""
        if not before or not after:
            return False

        # Get word analysis
        before_words = before.lower().split()
        after_words = after.lower().split()

        # Check if both sides have verbs (indicating separate commands)
        before_has_verb = any(
            word in self.pattern_learner.app_verbs | self.pattern_learner.system_verbs
            for word in before_words
        )
        after_has_verb = any(
            word in self.pattern_learner.app_verbs | self.pattern_learner.system_verbs
            for word in after_words[:3]
        )  # Check first 3 words of after

        if before_has_verb and after_has_verb:
            return True

        # Check if both sides mention apps
        before_has_app = any(
            self.pattern_learner.is_learned_app(word) for word in before_words
        )
        after_has_app = any(
            self.pattern_learner.is_learned_app(word) for word in after_words
        )

        if before_has_app and after_has_app and before_has_verb:
            return True

        # Don't split if it's part of a single concept
        single_concepts = {
            connector + "press enter",
            connector + "enter",
            connector + "return",
            "type",
            "write",
            "and then",
        }

        # Check if the connector is truly part of a single phrase
        full_text = (before + connector + after).lower()
        for concept in single_concepts:
            if concept in full_text:
                return False

        # Special handling for search/navigation commands
        # "search for X and Y" should not split, but "open X and search for Y" should
        if connector == " and " and "search for" in after.lower():
            # If before has an app operation, this should split
            if any(
                verb in before.lower() for verb in ["open", "launch", "start", "close"]
            ):
                return True

        # Don't split URLs or domains
        if self._contains_url_pattern(before + connector + after):
            url_start = before.rfind("http")
            if url_start == -1:
                url_start = before.rfind("www.")
            if url_start != -1:
                return False

        return True

    def _can_parallelize_commands(self, parts: List[str]) -> bool:
        """Dynamically determine if commands can be run in parallel"""
        if len(parts) < 2:
            return False

        # Analyze command dependencies
        command_analyses = []

        for i, part in enumerate(parts):
            words = part.lower().split()

            analysis = {
                "has_verb": any(
                    word
                    in self.pattern_learner.app_verbs
                    | self.pattern_learner.system_verbs
                    for word in words
                ),
                "has_app": any(
                    self.pattern_learner.is_learned_app(word) for word in words
                ),
                "has_dependency": False,
                "operation_type": None,
                "affects_state": False,
            }

            # Detect operation type
            for word in words:
                if word in self.pattern_learner.app_verbs:
                    if word in {"open", "launch", "start"}:
                        analysis["operation_type"] = "open"
                    elif word in {"close", "quit", "kill"}:
                        analysis["operation_type"] = "close"
                    break

            # Check for dependencies on previous commands
            dependency_indicators = {"then", "after", "next", "followed", "using"}
            if any(indicator in words for indicator in dependency_indicators):
                analysis["has_dependency"] = True

            # Check if command affects state that next command might depend on
            state_affecting = {"search", "type", "navigate", "click", "select", "focus"}
            if any(action in words for action in state_affecting):
                analysis["affects_state"] = True

            # Check for explicit references to previous results
            if i > 0:
                reference_words = {"it", "that", "there", "result"}
                if any(ref in words for ref in reference_words):
                    analysis["has_dependency"] = True

            command_analyses.append(analysis)

        # Determine if parallelizable
        # Commands can be parallel if:
        # 1. No command has dependencies
        # 2. No command affects state that others might use
        # 3. All are similar operation types

        has_dependencies = any(a["has_dependency"] for a in command_analyses)
        if has_dependencies:
            return False

        affects_state = any(a["affects_state"] for a in command_analyses)
        if affects_state:
            return False

        # Check operation types
        operation_types = [
            a["operation_type"] for a in command_analyses if a["operation_type"]
        ]
        if operation_types:
            # All same type = parallelizable
            return len(set(operation_types)) == 1

        # Default: if simple and independent, allow parallel
        all_simple = all(len(part.split()) <= 4 for part in parts)
        all_have_verbs = all(a["has_verb"] for a in command_analyses)

        return all_simple and all_have_verbs

    def _enhance_with_context(
        self, command: str, active_app: Optional[str], previous_result: Optional[Dict]
    ) -> str:
        """Enhance command with context from previous commands"""
        command_lower = command.lower()
        words = command_lower.split()

        # Dynamic pattern detection for navigation and search
        nav_indicators = {"go", "navigate", "browse", "visit", "open"}
        search_indicators = {"search", "find", "look", "google", "query"}

        # Check if this needs browser context
        has_nav = any(word in words for word in nav_indicators)
        has_search = any(word in words for word in search_indicators)

        if (has_nav or has_search) and active_app:
            # Check if active app is likely a browser (learned from system)
            browser_indicators = {"browser", "web", "internet"}
            is_browser = active_app.lower() in {"safari", "chrome", "firefox"} or any(
                indicator in active_app.lower() for indicator in browser_indicators
            )

            if is_browser:
                # Check if browser not already specified
                if not self.pattern_learner.is_learned_app(active_app):
                    # Learn this as a browser app
                    self.pattern_learner.learned_apps.add(active_app.lower())

                # Enhance command if browser not mentioned
                app_mentioned = any(
                    self.pattern_learner.is_learned_app(word) for word in words
                )
                if not app_mentioned:
                    # Add browser context
                    if has_search:
                        # Clean up the command - remove "and", "search", "search for" to get just the query
                        cleaned = command
                        # Remove leading "and" if present
                        if cleaned.lower().startswith("and "):
                            cleaned = cleaned[4:]
                        # Remove search-related words
                        cleaned = (
                            cleaned.replace("search for", "")
                            .replace("search", "")
                            .strip()
                        )
                        command = f"search in {active_app} for {cleaned}"
                    elif "go to" in command_lower:
                        command = command.replace(
                            "go to", f"tell {active_app} to go to"
                        )
                    else:
                        command = f"in {active_app} {command}"

        # Use previous result context if available
        if previous_result and previous_result.get("success"):
            # Could enhance with information from previous successful command
            pass

        return command

    def _parse_system_command(
        self, command_text: str
    ) -> Tuple[str, Optional[str], Dict[str, Any]]:
        """Dynamically parse system command to extract type, target, and parameters"""
        words = command_text.lower().split()
        command_type = None
        target = None
        params = {}

        # Detect command type based on verb patterns
        first_word = words[0] if words else ""

        # Tab/browser operations
        tab_indicators = {"tab", "tabs"}
        if any(indicator in words for indicator in tab_indicators):
            command_type = "tab_control"
            # Find browser if mentioned
            for word in words:
                if self.pattern_learner.is_learned_app(word):
                    # Check if it's likely a browser
                    if any(
                        browser_hint in word
                        for browser_hint in ["safari", "chrome", "firefox", "browser"]
                    ):
                        target = word
                        break
            # Extract URL if present
            url_patterns = ["go to", "navigate to", "and open", "open"]
            for pattern in url_patterns:
                if pattern in command_text.lower():
                    idx = command_text.lower().find(pattern)
                    url_part = command_text[idx + len(pattern) :].strip()
                    if url_part:
                        params["url"] = self._normalize_url(url_part)
                    break

        # App control operations
        elif first_word in self.pattern_learner.app_verbs:
            if first_word in {"open", "launch", "start"}:
                command_type = "app_open"
            elif first_word in {"close", "quit", "kill"}:
                command_type = "app_close"

            # Find target app
            for i, word in enumerate(words[1:], 1):
                if self.pattern_learner.is_learned_app(word):
                    target = word
                    break
                # Also check multi-word apps
                if i < len(words) - 1:
                    two_word = f"{word} {words[i+1]}"
                    if self.pattern_learner.is_learned_app(two_word):
                        target = two_word
                        break

        # System settings operations
        elif any(
            setting in words
            for setting in {"volume", "brightness", "wifi", "bluetooth", "screenshot"}
        ):
            command_type = "system_setting"
            # Determine which setting
            if "volume" in words:
                target = "volume"
                if "mute" in words:
                    params["action"] = "mute"
                elif "unmute" in words:
                    params["action"] = "unmute"
                else:
                    # Extract level
                    for word in words:
                        if word.isdigit():
                            params["level"] = int(word)
                            break
            elif "brightness" in words:
                target = "brightness"
                for word in words:
                    if word.isdigit():
                        params["level"] = int(word)
                        break
            elif "wifi" in words or "wi-fi" in words:
                target = "wifi"
                params["enable"] = "on" in words or "enable" in words
            elif "screenshot" in words:
                target = "screenshot"

        # Web operations
        elif any(
            web_verb in words
            for web_verb in {"search", "google", "browse", "navigate", "visit"}
        ):
            command_type = "web_action"
            # Determine specific action
            if "search" in words or "google" in words:
                params["action"] = "search"
                # Extract search query
                # Handle "search in X for Y" pattern first
                if (
                    "search in" in command_text.lower()
                    and " for " in command_text.lower()
                ):
                    # Extract query after "for"
                    for_idx = command_text.lower().find(" for ")
                    if for_idx != -1:
                        query = command_text[for_idx + 5 :].strip()
                        if query:
                            params["query"] = query
                            logger.info(
                                f"[PARSE] Extracted query from 'search in X for Y' pattern: '{query}'"
                            )
                else:
                    # Standard search patterns
                    search_patterns = ["search for", "google", "look up", "find"]
                    for pattern in search_patterns:
                        if pattern in command_text.lower():
                            idx = command_text.lower().find(pattern)
                            query = command_text[idx + len(pattern) :].strip()
                            if query:
                                params["query"] = query
                                logger.info(
                                    f"[PARSE] Extracted query from '{pattern}' pattern: '{query}'"
                                )
                                break
            else:
                params["action"] = "navigate"
                # Extract URL
                nav_patterns = ["go to", "navigate to", "visit", "browse to"]
                for pattern in nav_patterns:
                    if pattern in command_text.lower():
                        idx = command_text.lower().find(pattern)
                        url = command_text[idx + len(pattern) :].strip()
                        if url:
                            params["url"] = self._normalize_url(url)
                            break

            # Find browser if specified
            # Check both original words and full command text (in case of "search in X for Y")
            if "in " in command_text.lower():
                # Extract browser from "in [browser]" pattern
                in_match = re.search(r"\bin\s+(\w+)\s+", command_text.lower())
                if in_match:
                    potential_browser = in_match.group(1)
                    if self.pattern_learner.is_learned_app(potential_browser):
                        target = potential_browser

            # If not found, check individual words
            if not target:
                for word in words:
                    if self.pattern_learner.is_learned_app(word):
                        if any(
                            hint in word
                            for hint in ["safari", "chrome", "firefox", "browser"]
                        ):
                            target = word
                            break

        # Multi-tab searches
        if (
            "separate tabs" in command_text.lower()
            or "different tabs" in command_text.lower()
        ):
            command_type = "multi_tab_search"
            params["multi_tab"] = True

        # Typing operations
        elif "type" in words:
            command_type = "type_text"
            # Extract text to type
            idx = command_text.lower().find("type")
            text = command_text[idx + 4 :].strip()
            # Remove trailing instructions
            text = text.replace(" and press enter", "").replace(" and enter", "")
            params["text"] = text
            params["press_enter"] = "enter" in command_text.lower()

        return command_type or "unknown", target, params

    def _normalize_url(self, url: str) -> str:
        """Normalize URL input"""
        url = url.strip()

        # Handle common shortcuts
        if url.lower() in {"google", "google.com"}:
            return "https://google.com"

        # Add protocol if missing
        if not url.startswith(("http://", "https://")):
            if "." in url:
                return f"https://{url}"
            else:
                # Assume .com for single words
                return f"https://{url}.com"

        return url

    def _detect_default_browser(self) -> str:
        """Detect the default browser dynamically"""
        # Try to get default browser from system
        try:
            import subprocess

            result = subprocess.run(
                [
                    "defaults",
                    "read",
                    "com.apple.LaunchServices/com.apple.launchservices.secure",
                    "LSHandlers",
                ],
                capture_output=True,
                text=True,
            )
            if "safari" in result.stdout.lower():
                return "safari"
            elif "chrome" in result.stdout.lower():
                return "chrome"
            elif "firefox" in result.stdout.lower():
                return "firefox"
        except:
            pass

        # Default fallback
        return "safari"

    async def _execute_system_command(self, command_text: str) -> Dict[str, Any]:
        """Dynamically execute system commands without hardcoding"""

        # Check if this is actually a voice unlock command misclassified as system
        command_lower = command_text.lower()
        if ("voice" in command_lower and "unlock" in command_lower) or (
            "enable" in command_lower and "voice unlock" in command_lower
        ):
            # Redirect to voice unlock handler
            handler = await self._get_handler(CommandType.VOICE_UNLOCK)
            if handler:
                result = await handler.handle_command(command_text)
                return {
                    "success": result.get(
                        "success", result.get("type") == "voice_unlock"
                    ),
                    "response": result.get("message", result.get("response", "")),
                    "command_type": "voice_unlock",
                    **result,
                }

        try:
            from system_control.macos_controller import MacOSController
            from system_control.dynamic_app_controller import get_dynamic_app_controller

            macos_controller = MacOSController()
            dynamic_controller = get_dynamic_app_controller()

            # Check for lock/unlock screen commands first
            # Use the existing voice unlock integration for proper daemon support
            if (
                "lock" in command_lower or "unlock" in command_lower
            ) and "screen" in command_lower:
                logger.info(
                    f"[SYSTEM] Screen lock/unlock command detected, using voice unlock handler"
                )
                try:
                    from api.simple_unlock_handler import handle_unlock_command

                    # Pass the command to the existing unlock handler which integrates with the daemon
                    result = await handle_unlock_command(command_text)

                    # Ensure we return a properly formatted result
                    if isinstance(result, dict):
                        # Add command_type if not present
                        if "command_type" not in result:
                            result["command_type"] = (
                                "screen_lock"
                                if "lock" in command_lower
                                else "screen_unlock"
                            )
                        return result
                    else:
                        # Fallback to macos_controller if the unlock handler returns unexpected format
                        logger.warning(
                            f"[SYSTEM] Unexpected result from unlock handler, falling back"
                        )
                        result = await macos_controller.handle_command(command_text)
                        return result

                except ImportError:
                    logger.warning(
                        f"[SYSTEM] Simple unlock handler not available, using macos_controller"
                    )
                    result = await macos_controller.handle_command(command_text)
                    return result
                except Exception as e:
                    logger.error(
                        f"[SYSTEM] Error with unlock handler: {e}, falling back"
                    )
                    result = await macos_controller.handle_command(command_text)
                    return result

            # Parse command dynamically
            command_type, target, params = self._parse_system_command(command_text)

            logger.info(f"[SYSTEM] Parsing '{command_text}'")
            logger.info(
                f"[SYSTEM] Parsed: type={command_type}, target={target}, params={params}"
            )

            # Execute based on parsed command type
            if command_type == "tab_control":
                # Handle new tab operations
                browser = target or self._detect_default_browser()
                url = params.get("url")
                success, message = macos_controller.open_new_tab(browser, url)
                return {"success": success, "response": message}

            elif command_type == "app_open":
                # Open application
                if target:
                    success, message = await dynamic_controller.open_app_intelligently(
                        target
                    )
                    return {"success": success, "response": message}
                else:
                    return {
                        "success": False,
                        "response": "Please specify which app to open",
                    }

            elif command_type == "app_close":
                # Close application
                if target:
                    success, message = await dynamic_controller.close_app_intelligently(
                        target
                    )
                    return {"success": success, "response": message}
                else:
                    return {
                        "success": False,
                        "response": "Please specify which app to close",
                    }

            elif command_type == "system_setting":
                # Handle system settings
                if target == "volume":
                    action = params.get("action")
                    if action == "mute":
                        success, message = macos_controller.mute_volume(True)
                    elif action == "unmute":
                        success, message = macos_controller.mute_volume(False)
                    elif "level" in params:
                        success, message = macos_controller.set_volume(params["level"])
                    else:
                        return {
                            "success": False,
                            "response": "Please specify volume level or mute/unmute",
                        }
                    return {"success": success, "response": message}

                elif target == "brightness":
                    if "level" in params:
                        level = params["level"] / 100.0  # Convert to 0.0-1.0
                        success, message = macos_controller.adjust_brightness(level)
                    else:
                        return {
                            "success": False,
                            "response": "Please specify brightness level (0-100)",
                        }
                    return {"success": success, "response": message}

                elif target == "wifi":
                    enable = params.get("enable", True)
                    success, message = macos_controller.toggle_wifi(enable)
                    return {"success": success, "response": message}

                elif target == "screenshot":
                    success, message = macos_controller.take_screenshot()
                    return {"success": success, "response": message}

                else:
                    return {
                        "success": False,
                        "response": f"Unknown system setting: {target}",
                    }

            elif command_type == "web_action":
                # Handle web navigation and searches
                action = params.get("action")
                browser = target

                if action == "search" and "query" in params:
                    success, message = macos_controller.web_search(
                        params["query"], browser=browser
                    )
                    return {"success": success, "response": message}

                elif action == "navigate" and "url" in params:
                    success, message = macos_controller.open_url(params["url"], browser)
                    return {"success": success, "response": message}

                else:
                    return {
                        "success": False,
                        "response": "Please specify what to search for or where to navigate",
                    }

            elif command_type == "multi_tab_search":
                # Handle multi-tab searches dynamically
                return await self._handle_multi_tab_search(command_text, target)

            elif command_type == "type_text":
                # Handle typing
                text = params.get("text", "")
                press_enter = params.get("press_enter", False)
                browser = target

                if text:
                    success, message = macos_controller.type_in_browser(
                        text, browser, press_enter
                    )
                    return {"success": success, "response": message}
                else:
                    return {"success": False, "response": "Please specify what to type"}

            else:
                # Unknown command type - try to be helpful
                return {
                    "success": False,
                    "response": f"I'm not sure how to handle that command. I parsed it as '{command_type}' but couldn't execute it. Try rephrasing or being more specific.",
                }

        except Exception as e:
            logger.error(f"Error executing system command: {e}", exc_info=True)
            return {
                "success": False,
                "response": f"Failed to execute system command: {str(e)}",
            }

    async def _handle_multi_tab_search(
        self, command_text: str, browser: Optional[str]
    ) -> Dict[str, Any]:
        """Handle searches across multiple tabs dynamically"""
        try:
            from system_control.macos_controller import MacOSController
            from system_control.dynamic_app_controller import get_dynamic_app_controller

            macos_controller = MacOSController()
            dynamic_controller = get_dynamic_app_controller()

            # Extract search terms dynamically
            search_terms = self._extract_multi_search_terms(command_text)

            if not search_terms:
                return {
                    "success": False,
                    "response": "Couldn't identify what to search for",
                }

            # Detect browser if not specified
            if not browser:
                browser = self._detect_browser_from_context(command_text)

            # Open browser if needed
            if "open" in command_text.lower():
                success, _ = await dynamic_controller.open_app_intelligently(browser)
                if success:
                    await asyncio.sleep(1.5)

            # Open tabs for each search term
            results = []
            for i, term in enumerate(search_terms):
                if i == 0:
                    # First search in current tab
                    success, msg = macos_controller.web_search(term, browser=browser)
                else:
                    # Subsequent searches in new tabs
                    await asyncio.sleep(0.5)
                    search_url = f"https://google.com/search?q={term.replace(' ', '+')}"
                    success, msg = macos_controller.open_new_tab(browser, search_url)
                results.append(success)

            if all(results):
                terms_str = " and ".join(f"'{term}'" for term in search_terms)
                return {
                    "success": True,
                    "response": f"Searching for {terms_str} in separate tabs, Sir",
                }
            else:
                return {"success": False, "response": "Had trouble opening some tabs"}

        except Exception as e:
            logger.error(f"Error in multi-tab search: {e}", exc_info=True)
            return {
                "success": False,
                "response": f"Failed to perform multi-tab search: {str(e)}",
            }

    def _extract_multi_search_terms(self, command_text: str) -> List[str]:
        """Extract multiple search terms from command"""
        # Look for pattern like "search for X and Y and Z"
        patterns = ["search for", "google", "look up", "find"]

        for pattern in patterns:
            if pattern in command_text.lower():
                idx = command_text.lower().find(pattern)
                after_pattern = command_text[idx + len(pattern) :].strip()

                # Remove trailing instructions
                for instruction in [
                    "on separate tabs",
                    "in different tabs",
                    "on multiple tabs",
                ]:
                    if instruction in after_pattern.lower():
                        after_pattern = after_pattern[
                            : after_pattern.lower().find(instruction)
                        ].strip()

                # Split by 'and' to get individual terms
                terms = []
                parts = after_pattern.split(" and ")
                for part in parts:
                    part = part.strip()
                    if part and not any(
                        skip in part.lower() for skip in ["open", "close", "quit"]
                    ):
                        terms.append(part)

                return terms

        return []

    def _detect_browser_from_context(self, command_text: str) -> str:
        """Detect which browser is mentioned in command"""
        words = command_text.lower().split()

        # Check for any learned app that might be a browser
        for word in words:
            if self.pattern_learner.is_learned_app(word):
                # Check if it's likely a browser
                browser_hints = ["safari", "chrome", "firefox", "browser", "web"]
                if any(hint in word for hint in browser_hints):
                    return word

        # Default to detected default browser
        return self._detect_default_browser()


# Singleton instance
_unified_processor = None


def get_unified_processor(api_key: Optional[str] = None) -> UnifiedCommandProcessor:
    """Get or create the unified command processor"""
    global _unified_processor
    if _unified_processor is None:
        _unified_processor = UnifiedCommandProcessor(api_key)
    return _unified_processor
