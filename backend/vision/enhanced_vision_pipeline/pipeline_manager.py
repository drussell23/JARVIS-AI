#!/usr/bin/env python3
"""
Vision Pipeline Manager - Enhanced Vision Pipeline v1.0
========================================================

Orchestrates the complete 5-stage vision pipeline for Control Center navigation.

Architecture:
    Stage 1: Screen Region Segmentation
    Stage 2: Icon Pattern Recognition  
    Stage 3: Coordinate Calculation
    Stage 4: Multi-Model Validation
    Stage 5: Mouse Automation Execution

Author: Derek J. Russell
Date: October 2025
Version: 1.0
"""

import asyncio
import logging
import time
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from enum import Enum
import json

logger = logging.getLogger(__name__)


class PipelineStage(Enum):
    """Pipeline execution stages"""
    SCREEN_SEGMENTATION = "screen_segmentation"
    ICON_RECOGNITION = "icon_recognition"
    COORDINATE_CALCULATION = "coordinate_calculation"
    MULTI_MODEL_VALIDATION = "multi_model_validation"
    MOUSE_AUTOMATION = "mouse_automation"


@dataclass
class PipelineMetrics:
    """Real-time pipeline performance metrics"""
    total_executions: int = 0
    successful_executions: int = 0
    failed_executions: int = 0
    avg_latency_ms: float = 0.0
    stage_latencies: Dict[str, float] = field(default_factory=dict)
    detection_accuracy: float = 0.0
    coordinate_precision_px: float = 0.0
    recovery_success_rate: float = 0.0
    last_execution_time: Optional[datetime] = None


@dataclass
class PipelineResult:
    """Result from pipeline execution"""
    success: bool
    stage_completed: PipelineStage
    target_found: bool
    coordinates: Optional[Tuple[int, int]]
    confidence: float
    execution_time_ms: float
    metadata: Dict[str, Any]
    error: Optional[str] = None


class VisionPipelineManager:
    """
    Enhanced Vision Pipeline Manager
    
    Orchestrates multi-stage vision processing for UI navigation.
    Implements dynamic stage routing, error recovery, and performance monitoring.
    
    Features:
        - Async/await throughout
        - Zero hardcoding (fully config-driven)
        - Multi-model fusion (Claude + OpenCV + Template)
        - Physics-based coordinate calculation
        - Statistical validation (Monte Carlo)
        - Automatic error recovery
        - Real-time telemetry
    """
    
    def __init__(self, config_path: Optional[Path] = None):
        """Initialize vision pipeline manager"""
        # Load configuration
        if config_path is None:
            config_path = Path(__file__).parent.parent.parent / 'config' / 'vision_pipeline_config.json'
        
        self.config = self._load_config(config_path)
        self.metrics = PipelineMetrics()
        
        # Initialize pipeline stages (lazy loading)
        self.screen_analyzer = None
        self.icon_detector = None
        self.coord_calculator = None
        self.model_validator = None
        self.mouse_controller = None
        
        # Performance tracking
        self.stage_history: List[Dict[str, Any]] = []
        self.max_history = self.config.get('performance', {}).get('max_history_size', 100)
        
        # Recovery settings
        self.max_retries = self.config.get('recovery', {}).get('max_retries', 3)
        self.retry_delay = self.config.get('recovery', {}).get('retry_delay_ms', 500) / 1000.0
        
        logger.info("[VISION PIPELINE] Enhanced Vision Pipeline Manager initialized")
        logger.info(f"[VISION PIPELINE] Target latency: {self.config.get('performance', {}).get('target_latency_ms', 3000)}ms")
    
    def _load_config(self, config_path: Path) -> Dict[str, Any]:
        """Load pipeline configuration"""
        try:
            with open(config_path) as f:
                config = json.load(f)
            logger.info(f"[VISION PIPELINE] Loaded config from {config_path}")
            return config
        except FileNotFoundError:
            logger.warning(f"[VISION PIPELINE] Config not found, using defaults")
            return self._get_default_config()
        except Exception as e:
            logger.error(f"[VISION PIPELINE] Error loading config: {e}")
            return self._get_default_config()
    
    def _get_default_config(self) -> Dict[str, Any]:
        """Get default pipeline configuration"""
        return {
            "performance": {
                "target_latency_ms": 3000,
                "max_history_size": 100,
                "enable_telemetry": True
            },
            "detection": {
                "min_confidence": 0.85,
                "coordinate_precision_px": 2,
                "detection_accuracy_target": 0.99
            },
            "recovery": {
                "max_retries": 3,
                "retry_delay_ms": 500,
                "enable_fallback": True,
                "recovery_success_target": 0.95
            },
            "validation": {
                "multi_model_enabled": True,
                "monte_carlo_samples": 100,
                "outlier_rejection_threshold": 2.5
            },
            "stages": {
                "screen_segmentation": {"enabled": True, "timeout_ms": 500},
                "icon_recognition": {"enabled": True, "timeout_ms": 1000},
                "coordinate_calculation": {"enabled": True, "timeout_ms": 200},
                "multi_model_validation": {"enabled": True, "timeout_ms": 800},
                "mouse_automation": {"enabled": True, "timeout_ms": 500}
            }
        }
    
    async def initialize(self) -> bool:
        """Initialize all pipeline stages"""
        try:
            logger.info("[VISION PIPELINE] Initializing pipeline stages...")
            
            # Import and initialize stages
            from .screen_region_analyzer import ScreenRegionAnalyzer
            from .icon_detection_engine import IconDetectionEngine
            from .coordinate_calculator import CoordinateCalculator
            from .multi_model_validator import MultiModelValidator
            from .mouse_automation_controller import MouseAutomationController
            
            self.screen_analyzer = ScreenRegionAnalyzer(self.config)
            self.icon_detector = IconDetectionEngine(self.config)
            self.coord_calculator = CoordinateCalculator(self.config)
            self.model_validator = MultiModelValidator(self.config)
            self.mouse_controller = MouseAutomationController(self.config)
            
            # Initialize each stage
            await self.screen_analyzer.initialize()
            await self.icon_detector.initialize()
            await self.coord_calculator.initialize()
            await self.model_validator.initialize()
            await self.mouse_controller.initialize()
            
            logger.info("[VISION PIPELINE] âœ… All pipeline stages initialized")
            return True
            
        except Exception as e:
            logger.error(f"[VISION PIPELINE] âŒ Initialization failed: {e}")
            return False
    
    async def execute_pipeline(
        self,
        target: str,
        context: Optional[Dict[str, Any]] = None
    ) -> PipelineResult:
        """
        Execute complete vision pipeline
        
        Args:
            target: Target UI element to find ("control_center", "screen_mirroring", etc.)
            context: Optional context information
            
        Returns:
            PipelineResult with execution details
        """
        start_time = time.time()
        self.metrics.total_executions += 1
        
        logger.info(f"[VISION PIPELINE] ðŸš€ Starting pipeline for target: '{target}'")
        
        try:
            # Stage 1: Screen Region Segmentation
            stage1_result = await self._execute_stage_1(target, context)
            if not stage1_result['success']:
                return await self._handle_stage_failure(
                    PipelineStage.SCREEN_SEGMENTATION,
                    stage1_result,
                    start_time
                )
            
            # Stage 2: Icon Pattern Recognition
            stage2_result = await self._execute_stage_2(stage1_result, target, context)
            if not stage2_result['success']:
                return await self._handle_stage_failure(
                    PipelineStage.ICON_RECOGNITION,
                    stage2_result,
                    start_time
                )
            
            # Stage 3: Coordinate Calculation
            # Pass region offset from Stage 1
            if context is None:
                context = {}
            context['region_offset'] = (stage1_result['segmented_region'].x, stage1_result['segmented_region'].y)
            context['dpi_scale'] = stage1_result['segmented_region'].dpi_scale
            
            stage3_result = await self._execute_stage_3(stage2_result, context)
            if not stage3_result['success']:
                return await self._handle_stage_failure(
                    PipelineStage.COORDINATE_CALCULATION,
                    stage3_result,
                    start_time
                )
            
            # Stage 4: Multi-Model Validation
            stage4_result = await self._execute_stage_4(stage3_result, stage1_result, target, context)
            if not stage4_result['success']:
                return await self._handle_stage_failure(
                    PipelineStage.MULTI_MODEL_VALIDATION,
                    stage4_result,
                    start_time
                )
            
            # Stage 5: Mouse Automation Execution
            stage5_result = await self._execute_stage_5(stage4_result, context)
            if not stage5_result['success']:
                return await self._handle_stage_failure(
                    PipelineStage.MOUSE_AUTOMATION,
                    stage5_result,
                    start_time
                )
            
            # Success!
            execution_time = (time.time() - start_time) * 1000
            
            result = PipelineResult(
                success=True,
                stage_completed=PipelineStage.MOUSE_AUTOMATION,
                target_found=True,
                coordinates=stage4_result['validated_coordinates'],
                confidence=stage4_result['confidence'],
                execution_time_ms=execution_time,
                metadata={
                    'target': target,
                    'stage_results': {
                        'segmentation': stage1_result,
                        'recognition': stage2_result,
                        'calculation': stage3_result,
                        'validation': stage4_result,
                        'automation': stage5_result
                    }
                }
            )
            
            # Update metrics
            self.metrics.successful_executions += 1
            self._update_metrics(result)
            
            logger.info(f"[VISION PIPELINE] âœ… Pipeline completed in {execution_time:.1f}ms")
            logger.info(f"[VISION PIPELINE] Target found at {result.coordinates} (confidence: {result.confidence:.2%})")
            
            return result
            
        except Exception as e:
            logger.error(f"[VISION PIPELINE] âŒ Pipeline execution failed: {e}", exc_info=True)
            
            execution_time = (time.time() - start_time) * 1000
            self.metrics.failed_executions += 1
            
            return PipelineResult(
                success=False,
                stage_completed=PipelineStage.SCREEN_SEGMENTATION,
                target_found=False,
                coordinates=None,
                confidence=0.0,
                execution_time_ms=execution_time,
                metadata={'error': str(e)},
                error=str(e)
            )
    
    async def _execute_stage_1(
        self,
        target: str,
        context: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Stage 1: Screen Region Segmentation"""
        logger.info("[VISION PIPELINE] Stage 1: Screen Region Segmentation")
        
        start_time = time.time()
        
        try:
            result = await self.screen_analyzer.analyze_region(target, context)
            
            stage_time = (time.time() - start_time) * 1000
            self.metrics.stage_latencies['screen_segmentation'] = stage_time
            
            logger.info(f"[VISION PIPELINE] Stage 1 completed in {stage_time:.1f}ms")
            
            return result
            
        except Exception as e:
            logger.error(f"[VISION PIPELINE] Stage 1 failed: {e}")
            return {'success': False, 'error': str(e)}
    
    async def _execute_stage_2(
        self,
        stage1_result: Dict[str, Any],
        target: str,
        context: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Stage 2: Icon Pattern Recognition"""
        logger.info("[VISION PIPELINE] Stage 2: Icon Pattern Recognition")
        
        start_time = time.time()
        
        try:
            result = await self.icon_detector.detect_icon(
                stage1_result['segmented_region'],
                target,
                context
            )
            
            stage_time = (time.time() - start_time) * 1000
            self.metrics.stage_latencies['icon_recognition'] = stage_time
            
            logger.info(f"[VISION PIPELINE] Stage 2 completed in {stage_time:.1f}ms")
            
            return result
            
        except Exception as e:
            logger.error(f"[VISION PIPELINE] Stage 2 failed: {e}")
            return {'success': False, 'error': str(e)}
    
    async def _execute_stage_3(
        self,
        stage2_result: Dict[str, Any],
        context: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Stage 3: Coordinate Calculation"""
        logger.info("[VISION PIPELINE] Stage 3: Coordinate Calculation")
        
        start_time = time.time()
        
        try:
            result = await self.coord_calculator.calculate_coordinates(
                stage2_result['detection_results'],
                context
            )
            
            stage_time = (time.time() - start_time) * 1000
            self.metrics.stage_latencies['coordinate_calculation'] = stage_time
            
            logger.info(f"[VISION PIPELINE] Stage 3 completed in {stage_time:.1f}ms")
            
            return result
            
        except Exception as e:
            logger.error(f"[VISION PIPELINE] Stage 3 failed: {e}")
            return {'success': False, 'error': str(e)}
    
    async def _execute_stage_4(
        self,
        stage3_result: Dict[str, Any],
        stage1_result: Dict[str, Any],
        target: str,
        context: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Stage 4: Multi-Model Validation"""
        logger.info("[VISION PIPELINE] Stage 4: Multi-Model Validation")
        
        start_time = time.time()
        
        try:
            result = await self.model_validator.validate(
                stage3_result['calculated_coordinates'],
                stage1_result['segmented_region'],
                target,
                context
            )
            
            stage_time = (time.time() - start_time) * 1000
            self.metrics.stage_latencies['multi_model_validation'] = stage_time
            
            logger.info(f"[VISION PIPELINE] Stage 4 completed in {stage_time:.1f}ms")
            
            return result
            
        except Exception as e:
            logger.error(f"[VISION PIPELINE] Stage 4 failed: {e}")
            return {'success': False, 'error': str(e)}
    
    async def _execute_stage_5(
        self,
        stage4_result: Dict[str, Any],
        context: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Stage 5: Mouse Automation Execution"""
        logger.info("[VISION PIPELINE] Stage 5: Mouse Automation Execution")
        
        start_time = time.time()
        
        try:
            result = await self.mouse_controller.execute_click(
                stage4_result['validated_coordinates'],
                context
            )
            
            stage_time = (time.time() - start_time) * 1000
            self.metrics.stage_latencies['mouse_automation'] = stage_time
            
            logger.info(f"[VISION PIPELINE] Stage 5 completed in {stage_time:.1f}ms")
            
            return result
            
        except Exception as e:
            logger.error(f"[VISION PIPELINE] Stage 5 failed: {e}")
            return {'success': False, 'error': str(e)}
    
    async def _handle_stage_failure(
        self,
        failed_stage: PipelineStage,
        stage_result: Dict[str, Any],
        start_time: float
    ) -> PipelineResult:
        """Handle pipeline stage failure with recovery"""
        logger.warning(f"[VISION PIPELINE] Stage {failed_stage.value} failed")
        
        execution_time = (time.time() - start_time) * 1000
        self.metrics.failed_executions += 1
        
        return PipelineResult(
            success=False,
            stage_completed=failed_stage,
            target_found=False,
            coordinates=None,
            confidence=0.0,
            execution_time_ms=execution_time,
            metadata=stage_result,
            error=stage_result.get('error', 'Unknown error')
        )
    
    def _update_metrics(self, result: PipelineResult):
        """Update pipeline performance metrics"""
        # Update average latency
        total_time = self.metrics.avg_latency_ms * (self.metrics.successful_executions - 1)
        self.metrics.avg_latency_ms = (total_time + result.execution_time_ms) / self.metrics.successful_executions
        
        # Update detection accuracy
        if result.target_found:
            self.metrics.detection_accuracy = (
                self.metrics.detection_accuracy * (self.metrics.successful_executions - 1) + 1.0
            ) / self.metrics.successful_executions
        
        # Update coordinate precision
        if result.coordinates:
            self.metrics.coordinate_precision_px = self.config['detection']['coordinate_precision_px']
        
        # Update last execution time
        self.metrics.last_execution_time = datetime.now()
        
        # Add to history
        self.stage_history.append({
            'timestamp': datetime.now().isoformat(),
            'success': result.success,
            'latency_ms': result.execution_time_ms,
            'confidence': result.confidence
        })
        
        # Trim history if needed
        if len(self.stage_history) > self.max_history:
            self.stage_history = self.stage_history[-self.max_history:]
    
    def get_metrics(self) -> Dict[str, Any]:
        """Get current pipeline metrics"""
        success_rate = 0.0
        if self.metrics.total_executions > 0:
            success_rate = self.metrics.successful_executions / self.metrics.total_executions
        
        return {
            'total_executions': self.metrics.total_executions,
            'successful_executions': self.metrics.successful_executions,
            'failed_executions': self.metrics.failed_executions,
            'success_rate': success_rate,
            'avg_latency_ms': round(self.metrics.avg_latency_ms, 2),
            'stage_latencies': {k: round(v, 2) for k, v in self.metrics.stage_latencies.items()},
            'detection_accuracy': round(self.metrics.detection_accuracy, 4),
            'coordinate_precision_px': self.metrics.coordinate_precision_px,
            'last_execution': self.metrics.last_execution_time.isoformat() if self.metrics.last_execution_time else None
        }
    
    def get_status(self) -> Dict[str, Any]:
        """Get pipeline status"""
        return {
            'initialized': all([
                self.screen_analyzer,
                self.icon_detector,
                self.coord_calculator,
                self.model_validator,
                self.mouse_controller
            ]),
            'config_loaded': self.config is not None,
            'metrics': self.get_metrics(),
            'stages_enabled': {
                stage: self.config['stages'][stage]['enabled']
                for stage in self.config['stages']
            }
        }


# Singleton instance
_pipeline_instance: Optional[VisionPipelineManager] = None


def get_vision_pipeline(config_path: Optional[Path] = None) -> VisionPipelineManager:
    """Get singleton vision pipeline instance"""
    global _pipeline_instance
    if _pipeline_instance is None:
        _pipeline_instance = VisionPipelineManager(config_path)
    return _pipeline_instance
