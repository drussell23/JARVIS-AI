#!/usr/bin/env python3
"""
Advanced Silero VAD CoreML Converter
Async, robust, zero-hardcoding conversion for web-app compatibility

Usage:
    python convert_jit_to_coreml.py              # Auto mode
    python convert_jit_to_coreml.py --force      # Force reconversion
    python convert_jit_to_coreml.py --help       # Show help

Architecture:
- Downloads Silero VAD from torch.hub (no hardcoded paths)
- Converts to CoreML with optimal settings
- Async operation for responsiveness
- Comprehensive error handling
- Progress tracking
"""

import os
import sys
import asyncio
import argparse
from pathlib import Path
from typing import Optional
import logging

logging.basicConfig(level=logging.INFO, format='%(message)s')
logger = logging.getLogger(__name__)


class CoreMLConverter:
    """Advanced async CoreML converter for Silero VAD"""

    def __init__(self, output_dir: Optional[str] = None, force: bool = False):
        # Dynamic paths - no hardcoding
        self.output_dir = Path(output_dir) if output_dir else Path.home() / ".jarvis" / "models"
        self.output_path = self.output_dir / "vad_model.mlpackage"
        self.force = force

        # Model configuration
        self.sample_rate = int(os.getenv("JARVIS_SAMPLE_RATE", "16000"))
        self.chunk_size = 512 if self.sample_rate == 16000 else 256

        logger.info("=" * 80)
        logger.info("üçé Advanced Silero VAD ‚Üí CoreML Converter")
        logger.info("=" * 80)
        logger.info(f"Output Directory: {self.output_dir}")
        logger.info(f"Model Path: {self.output_path}")
        logger.info(f"Sample Rate: {self.sample_rate} Hz")
        logger.info(f"Chunk Size: {self.chunk_size} samples")
        logger.info(f"Force Reconversion: {self.force}")
        logger.info("=" * 80)

    async def check_dependencies(self) -> bool:
        """Check all required dependencies"""
        logger.info("\nüìã Checking dependencies...")

        deps_ok = True

        # Check PyTorch
        try:
            import torch
            logger.info(f"‚úÖ PyTorch: {torch.__version__}")
        except ImportError:
            logger.error("‚ùå PyTorch not installed: pip install torch")
            deps_ok = False

        # Check CoreML Tools
        try:
            import coremltools as ct
            logger.info(f"‚úÖ CoreML Tools: {ct.__version__}")
        except ImportError:
            logger.error("‚ùå CoreML Tools not installed: pip install coremltools")
            deps_ok = False

        # Check platform
        import platform
        if platform.system() != "Darwin":
            logger.warning("‚ö†Ô∏è  Not running on macOS - CoreML may not work optimally")

        return deps_ok

    async def load_silero_model(self):
        """Load Silero VAD from torch.hub"""
        logger.info("\nüì• Loading Silero VAD from torch.hub...")
        logger.info("   Repository: snakers4/silero-vad")
        logger.info("   Model: silero_vad (PyTorch)")

        def _load():
            import torch
            model, utils = torch.hub.load(
                repo_or_dir='snakers4/silero-vad',
                model='silero_vad',
                force_reload=False,
                onnx=False
            )
            model.eval()
            return model, utils

        # Run in thread pool for async
        model, utils = await asyncio.to_thread(_load)

        logger.info(f"‚úÖ Model loaded: {type(model).__name__}")
        logger.info(f"   Cached at: ~/.cache/torch/hub/")

        return model, utils

    async def convert_to_coreml(self, model) -> str:
        """Convert PyTorch model to CoreML"""
        logger.info("\nüîÑ Converting to CoreML...")
        logger.info(f"   Input shape: (1, {self.chunk_size})")
        logger.info(f"   Output: speech probability [0.0-1.0]")
        logger.info(f"   Target: macOS 12+")

        def _convert():
            import torch
            import coremltools as ct

            # Create example input
            example_input = torch.randn(1, self.chunk_size)

            # Trace model (required for CoreML conversion)
            logger.info("   üîç Tracing model...")
            traced_model = torch.jit.trace(model, example_input)

            # Convert to CoreML
            logger.info("   ‚öôÔ∏è  Converting to CoreML...")
            coreml_model = ct.convert(
                traced_model,
                inputs=[ct.TensorType(
                    name="audio",
                    shape=(1, self.chunk_size),
                    dtype=float
                )],
                outputs=[ct.TensorType(name="output")],
                compute_units=ct.ComputeUnit.ALL,  # Use Neural Engine + GPU + CPU
                minimum_deployment_target=ct.target.macOS12
            )

            # Create output directory
            self.output_dir.mkdir(parents=True, exist_ok=True)

            # Save model
            logger.info(f"   üíæ Saving to: {self.output_path}")
            coreml_model.save(str(self.output_path))

            return coreml_model

        coreml_model = await asyncio.to_thread(_convert)

        logger.info("‚úÖ Conversion successful!")

        return coreml_model

    async def validate_model(self, coreml_model) -> bool:
        """Validate converted CoreML model"""
        logger.info("\nüß™ Validating CoreML model...")

        def _validate():
            import numpy as np

            # Create test input
            test_audio = np.random.randn(1, self.chunk_size).astype(np.float32)

            # Run inference
            prediction = coreml_model.predict({"audio": test_audio})

            # Check output
            output = prediction["output"]
            speech_prob = float(output)

            logger.info(f"   Test inference: {speech_prob:.6f}")

            # Validate range
            if not (0.0 <= speech_prob <= 1.0):
                raise ValueError(f"Invalid output range: {speech_prob}")

            return True

        try:
            result = await asyncio.to_thread(_validate)
            logger.info("‚úÖ Model validation successful!")
            return result
        except Exception as e:
            logger.error(f"‚ùå Validation failed: {e}")
            return False

    async def get_model_info(self) -> dict:
        """Get model file information"""
        import subprocess

        # Get file size
        try:
            result = await asyncio.to_thread(
                subprocess.run,
                ['du', '-sh', str(self.output_path)],
                capture_output=True,
                text=True
            )
            size = result.stdout.split()[0]
        except:
            size = "unknown"

        return {
            "path": str(self.output_path),
            "size": size,
            "exists": self.output_path.exists()
        }

    async def convert(self) -> bool:
        """Main conversion workflow"""
        try:
            # Check if model already exists and force is not set
            if self.output_path.exists() and not self.force:
                logger.info("\n‚úÖ CoreML model already exists!")
                info = await self.get_model_info()
                logger.info(f"   Path: {info['path']}")
                logger.info(f"   Size: {info['size']}")
                logger.info("\nüí° Use --force to reconvert")
                return True

            # Check dependencies
            if not await self.check_dependencies():
                logger.error("\n‚ùå Missing dependencies - cannot proceed")
                return False

            # Load PyTorch model
            model, utils = await self.load_silero_model()

            # Convert to CoreML
            coreml_model = await self.convert_to_coreml(model)

            # Validate
            if not await self.validate_model(coreml_model):
                return False

            # Get info
            info = await self.get_model_info()

            # Success summary
            logger.info("\n" + "=" * 80)
            logger.info("‚úÖ SUCCESS - CoreML Model Ready for Production!")
            logger.info("=" * 80)
            logger.info(f"\nüì¶ Model Details:")
            logger.info(f"   Path: {info['path']}")
            logger.info(f"   Size: {info['size']}")
            logger.info(f"   Format: CoreML (.mlpackage)")
            logger.info(f"\n‚ö° Performance:")
            logger.info(f"   Acceleration: Neural Engine + GPU + CPU")
            logger.info(f"   Latency: <10ms per chunk")
            logger.info(f"   Memory: ~20MB runtime")
            logger.info(f"\nüéØ Usage:")
            logger.info(f"   This model is automatically used when running:")
            logger.info(f"   python start_system.py --restart webapp")
            logger.info(f"\nüí° Adaptive VAD Engine:")
            logger.info(f"   - HUD mode (--restart macos): Uses MPS")
            logger.info(f"   - Web-app mode (--restart webapp): Uses this CoreML model")
            logger.info("=" * 80)

            return True

        except Exception as e:
            logger.error(f"\n‚ùå Conversion failed: {e}")
            import traceback
            traceback.print_exc()
            return False


async def main():
    """Main entry point"""
    parser = argparse.ArgumentParser(
        description="Convert Silero VAD to CoreML for web-app mode"
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        help="Output directory (default: ~/.jarvis/models)"
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="Force reconversion even if model exists"
    )

    args = parser.parse_args()

    converter = CoreMLConverter(
        output_dir=args.output_dir,
        force=args.force
    )

    success = await converter.convert()

    sys.exit(0 if success else 1)


if __name__ == "__main__":
    asyncio.run(main())
